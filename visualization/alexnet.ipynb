{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_3 (InputLayer)             (None, 3, 227, 227)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_1 (Convolution2D)           (None, 96, 55, 55)    34944       input_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_5 (MaxPooling2D)    (None, 96, 27, 27)    0           conv_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convpool_1 (Lambda)              (None, 96, 27, 27)    0           maxpooling2d_5[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_9 (ZeroPadding2D)  (None, 96, 31, 31)    0           convpool_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)               (None, 48, 31, 31)    0           zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)               (None, 48, 31, 31)    0           zeropadding2d_9[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv_2_1 (Convolution2D)         (None, 128, 27, 27)   153728      lambda_15[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv_2_2 (Convolution2D)         (None, 128, 27, 27)   153728      lambda_16[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv_2 (Merge)                   (None, 256, 27, 27)   0           conv_2_1[0][0]                   \n",
      "                                                                   conv_2_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_6 (MaxPooling2D)    (None, 256, 13, 13)   0           conv_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)               (None, 256, 13, 13)   0           maxpooling2d_6[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_10 (ZeroPadding2D) (None, 256, 15, 15)   0           lambda_17[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv_3 (Convolution2D)           (None, 384, 13, 13)   885120      zeropadding2d_10[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_11 (ZeroPadding2D) (None, 384, 15, 15)   0           conv_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)               (None, 192, 15, 15)   0           zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)               (None, 192, 15, 15)   0           zeropadding2d_11[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv_4_1 (Convolution2D)         (None, 192, 13, 13)   331968      lambda_18[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv_4_2 (Convolution2D)         (None, 192, 13, 13)   331968      lambda_19[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv_4 (Merge)                   (None, 384, 13, 13)   0           conv_4_1[0][0]                   \n",
      "                                                                   conv_4_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_12 (ZeroPadding2D) (None, 384, 15, 15)   0           conv_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)               (None, 192, 15, 15)   0           zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)               (None, 192, 15, 15)   0           zeropadding2d_12[0][0]           \n",
      "____________________________________________________________________________________________________\n",
      "conv_5_1 (Convolution2D)         (None, 128, 13, 13)   221312      lambda_20[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv_5_2 (Convolution2D)         (None, 128, 13, 13)   221312      lambda_21[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv_5 (Merge)                   (None, 256, 13, 13)   0           conv_5_1[0][0]                   \n",
      "                                                                   conv_5_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convpool_5 (MaxPooling2D)        (None, 256, 6, 6)     0           conv_5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                (None, 9216)          0           convpool_5[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          37752832    flatten[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 4096)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_5[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 56,868,224\n",
      "Trainable params: 56,868,224\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Processing filter 0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The index list is longer (size 4) than the number of dimensions of the tensor(namely 2). You are asking for a dimension of the tensor that does not exist! You might need to use dimshuffle to add extra dimension to your tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-6d2eeb58778f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_dim_ordering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'th'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/machine/anaconda2/lib/python2.7/site-packages/theano/tensor/var.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    581\u001b[0m                     self, *theano.tensor.subtensor.Subtensor.collapse(\n\u001b[1;32m    582\u001b[0m                         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                         lambda entry: isinstance(entry, Variable)))\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/machine/anaconda2/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \"\"\"\n\u001b[1;32m    603\u001b[0m         \u001b[0mreturn_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'return_list'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 604\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    605\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_test_value\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'off'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/machine/anaconda2/lib/python2.7/site-packages/theano/tensor/subtensor.pyc\u001b[0m in \u001b[0;36mmake_node\u001b[0;34m(self, x, *inputs)\u001b[0m\n\u001b[1;32m    484\u001b[0m                 len(idx_list), x.type.ndim))\n\u001b[1;32m    485\u001b[0m             \u001b[0mexception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtensor_invalid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         input_types = Subtensor.collapse(idx_list,\n",
      "\u001b[0;31mValueError\u001b[0m: The index list is longer (size 4) than the number of dimensions of the tensor(namely 2). You are asking for a dimension of the tensor that does not exist! You might need to use dimshuffle to add extra dimension to your tensor."
     ]
    }
   ],
   "source": [
    "'''Visualization of the filters of VGG16, via gradient ascent in input space.\n",
    "\n",
    "This script can run on CPU in a few minutes (with the TensorFlow backend).\n",
    "\n",
    "Results example: http://i.imgur.com/4nj4KjN.jpg\n",
    "'''\n",
    "from __future__ import print_function\n",
    "from scipy.misc import imsave\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "from model import alexnet\n",
    "# dimensions of the generated pictures for each filter.\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "\n",
    "# the name of the layer we want to visualize\n",
    "# (see model definition at keras/applications/vgg16.py)\n",
    "layer_name = 'dense_2'\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "# build the VGG16 network with ImageNet weights\n",
    "model = alexnet(\"alex_finetune567_aug_weights1.h5\", nb_class=100)\n",
    "print('Model loaded.')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# this is the placeholder for the input images\n",
    "input_img = model.input\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
    "\n",
    "\n",
    "kept_filters = []\n",
    "for filter_index in range(0, 20):\n",
    "    # we only scan through the first 200 filters,\n",
    "    # but there are actually 512 of them\n",
    "    print('Processing filter %d' % filter_index)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = normalize(grads)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # step size for gradient ascent\n",
    "    step = 1.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        input_img_data = np.random.random((1, 3, img_width, img_height))\n",
    "    else:\n",
    "        input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "\n",
    "    # we run gradient ascent for 20 steps\n",
    "    for i in range(100):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "        print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "\n",
    "    # decode the resulting input image\n",
    "    if loss_value > 0:\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        kept_filters.append((img, loss_value))\n",
    "    end_time = time.time()\n",
    "    print('Filter %d processed in %ds' % (filter_index, end_time - start_time))\n",
    "\n",
    "# we will stich the best 64 filters on a 8 x 8 grid.\n",
    "n = 4\n",
    "\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 64 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n",
    "\n",
    "# build a black picture with enough space for\n",
    "# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "margin = 5\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n",
    "                         (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
    "\n",
    "# save the result to disk\n",
    "imsave('stitched_filters_%dx%d.png' % (n, n), stitched_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
