{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input_2 (InputLayer)             (None, 3, 227, 227)   0                                            \n",
      "____________________________________________________________________________________________________\n",
      "conv_1 (Convolution2D)           (None, 96, 55, 55)    34944       input_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 96, 27, 27)    0           conv_1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "convpool_1 (Lambda)              (None, 96, 27, 27)    0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_5 (ZeroPadding2D)  (None, 96, 31, 31)    0           convpool_1[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)                (None, 48, 31, 31)    0           zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)                (None, 48, 31, 31)    0           zeropadding2d_5[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv_2_1 (Convolution2D)         (None, 128, 27, 27)   153728      lambda_8[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv_2_2 (Convolution2D)         (None, 128, 27, 27)   153728      lambda_9[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "conv_2 (Merge)                   (None, 256, 27, 27)   0           conv_2_1[0][0]                   \n",
      "                                                                   conv_2_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_4 (MaxPooling2D)    (None, 256, 13, 13)   0           conv_2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)               (None, 256, 13, 13)   0           maxpooling2d_4[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_6 (ZeroPadding2D)  (None, 256, 15, 15)   0           lambda_10[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv_3 (Convolution2D)           (None, 384, 13, 13)   885120      zeropadding2d_6[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_7 (ZeroPadding2D)  (None, 384, 15, 15)   0           conv_3[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)               (None, 192, 15, 15)   0           zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)               (None, 192, 15, 15)   0           zeropadding2d_7[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv_4_1 (Convolution2D)         (None, 192, 13, 13)   331968      lambda_11[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv_4_2 (Convolution2D)         (None, 192, 13, 13)   331968      lambda_12[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv_4 (Merge)                   (None, 384, 13, 13)   0           conv_4_1[0][0]                   \n",
      "                                                                   conv_4_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "zeropadding2d_8 (ZeroPadding2D)  (None, 384, 15, 15)   0           conv_4[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)               (None, 192, 15, 15)   0           zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)               (None, 192, 15, 15)   0           zeropadding2d_8[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "conv_5_1 (Convolution2D)         (None, 128, 13, 13)   221312      lambda_13[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv_5_2 (Convolution2D)         (None, 128, 13, 13)   221312      lambda_14[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "conv_5 (Merge)                   (None, 256, 13, 13)   0           conv_5_1[0][0]                   \n",
      "                                                                   conv_5_2[0][0]                   \n",
      "____________________________________________________________________________________________________\n",
      "convpool_5 (MaxPooling2D)        (None, 256, 6, 6)     0           conv_5[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "flatten (Flatten)                (None, 9216)          0           convpool_5[0][0]                 \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 4096)          37752832    flatten[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 4096)          0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 4096)          16781312    dropout_3[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 56,868,224\n",
      "Trainable params: 56,868,224\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "Processing filter 0\n",
      "Filter 0 processed in 3s\n",
      "Processing filter 1\n",
      "Filter 1 processed in 2s\n",
      "Processing filter 2\n",
      "Filter 2 processed in 2s\n",
      "Processing filter 3\n",
      "Filter 3 processed in 0s\n",
      "Processing filter 4\n",
      "Filter 4 processed in 3s\n",
      "Processing filter 5\n",
      "Filter 5 processed in 3s\n",
      "Processing filter 6\n",
      "Filter 6 processed in 3s\n",
      "Processing filter 7\n",
      "Filter 7 processed in 3s\n",
      "Processing filter 8\n",
      "Filter 8 processed in 2s\n",
      "Processing filter 9\n",
      "Filter 9 processed in 2s\n",
      "Processing filter 10\n",
      "Filter 10 processed in 3s\n",
      "Processing filter 11\n",
      "Filter 11 processed in 3s\n",
      "Processing filter 12\n",
      "Filter 12 processed in 3s\n",
      "Processing filter 13\n",
      "Filter 13 processed in 3s\n",
      "Processing filter 14\n",
      "Filter 14 processed in 2s\n",
      "Processing filter 15\n",
      "Filter 15 processed in 2s\n",
      "Processing filter 16\n",
      "Filter 16 processed in 2s\n",
      "Processing filter 17\n",
      "Filter 17 processed in 2s\n",
      "Processing filter 18\n",
      "Filter 18 processed in 3s\n",
      "Processing filter 19\n",
      "Filter 19 processed in 3s\n"
     ]
    }
   ],
   "source": [
    "'''Visualization of the filters of VGG16, via gradient ascent in input space.\n",
    "\n",
    "This script can run on CPU in a few minutes (with the TensorFlow backend).\n",
    "\n",
    "Results example: http://i.imgur.com/4nj4KjN.jpg\n",
    "'''\n",
    "from __future__ import print_function\n",
    "from scipy.misc import imsave\n",
    "import numpy as np\n",
    "import time\n",
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "from model import alexnet\n",
    "import scipy.misc\n",
    "import time\n",
    "# dimensions of the generated pictures for each filter.\n",
    "img_width = 128\n",
    "img_height = 128\n",
    "\n",
    "# the name of the layer we want to visualize\n",
    "# (see model definition at keras/applications/vgg16.py)\n",
    "layer_name = 'conv_1'\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "# build the VGG16 network with ImageNet weights\n",
    "model = alexnet(\"alex_finetune567_aug_weights1.h5\", nb_class=100)\n",
    "print('Model loaded.')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# this is the placeholder for the input images\n",
    "input_img = model.input\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
    "\n",
    "\n",
    "kept_filters = []\n",
    "for filter_index in range(0, 20):\n",
    "    # we only scan through the first 200 filters,\n",
    "    # but there are actually 512 of them\n",
    "    print('Processing filter %d' % filter_index)\n",
    "    start_time = time.time()\n",
    "\n",
    "    # we build a loss function that maximizes the activation\n",
    "    # of the nth filter of the layer considered\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        loss = K.mean(layer_output[:, filter_index, :, :])\n",
    "    else:\n",
    "        loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "    # we compute the gradient of the input picture wrt this loss\n",
    "    grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "    # normalization trick: we normalize the gradient\n",
    "    grads = normalize(grads)\n",
    "\n",
    "    # this function returns the loss and grads given the input picture\n",
    "    iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "    # step size for gradient ascent\n",
    "    step = 1.\n",
    "\n",
    "    # we start from a gray image with some random noise\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        #input_img_data = np.random.random((1, 3, img_width, img_height))\n",
    "        input_img_data = scipy.misc.imresize(scipy.misc.imread(\"../dataset/food10/AisKacang/AisKacang (2).jpg\"), (img_width,img_height)) \n",
    "        input_img_data = input_img_data.transpose((2, 0, 1))\n",
    "        input_img_data = np.expand_dims(input_img_data, axis=0)\n",
    "        \n",
    "        #(1,128,128,3)\n",
    "        \n",
    "    else:\n",
    "        input_img_data = np.random.random((1, img_width, img_height, 3))\n",
    "    input_img_data = (input_img_data - 0.5) * 20 + 128\n",
    "    \n",
    "    # we run gradient ascent for 20 steps\n",
    "    for i in range(2000):\n",
    "        loss_value, grads_value = iterate([input_img_data])\n",
    "        input_img_data += grads_value * step\n",
    "\n",
    "        #print('Current loss value:', loss_value)\n",
    "        if loss_value <= 0.:\n",
    "            # some filters get stuck to 0, we can skip them\n",
    "            break\n",
    "\n",
    "    # decode the resulting input image\n",
    "    if loss_value > 0:\n",
    "        img = deprocess_image(input_img_data[0])\n",
    "        kept_filters.append((img, loss_value))\n",
    "    end_time = time.time()\n",
    "    print('Filter %d processed in %ds' % (filter_index, end_time - start_time))\n",
    "\n",
    "# we will stich the best 64 filters on a 8 x 8 grid.\n",
    "n = 4\n",
    "\n",
    "# the filters that have the highest loss are assumed to be better-looking.\n",
    "# we will only keep the top 64 filters.\n",
    "kept_filters.sort(key=lambda x: x[1], reverse=True)\n",
    "kept_filters = kept_filters[:n * n]\n",
    "\n",
    "# build a black picture with enough space for\n",
    "# our 8 x 8 filters of size 128 x 128, with a 5px margin in between\n",
    "margin = 5\n",
    "width = n * img_width + (n - 1) * margin\n",
    "height = n * img_height + (n - 1) * margin\n",
    "stitched_filters = np.zeros((width, height, 3))\n",
    "\n",
    "# fill the picture with our saved filters\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        img, loss = kept_filters[i * n + j]\n",
    "        stitched_filters[(img_width + margin) * i: (img_width + margin) * i + img_width,\n",
    "                         (img_height + margin) * j: (img_height + margin) * j + img_height, :] = img\n",
    "\n",
    "# save the result to disk\n",
    "\n",
    "imsave('food2stitched_filters_%dx%d.png' % (n, n), stitched_filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
