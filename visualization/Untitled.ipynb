{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2\n",
      "conv_1\n",
      "maxpooling2d_3\n",
      "convpool_1\n",
      "zeropadding2d_17\n",
      "convolution2d_7 - (128, 48, 5, 5)\n",
      "convolution2d_8 - (128, 48, 5, 5)\n",
      "zeropadding2d_18\n",
      "zeropadding2d_20\n",
      "lrn2d_7\n",
      "lrn2d_8\n",
      "zeropadding2d_19\n",
      "zeropadding2d_21\n",
      "conv_2\n",
      "maxpooling2d_4\n",
      "lambda_2\n",
      "zeropadding2d_22\n",
      "conv_3\n",
      "zeropadding2d_23\n",
      "convolution2d_9 - (192, 192, 3, 3)\n",
      "convolution2d_10 - (192, 192, 3, 3)\n",
      "zeropadding2d_24\n",
      "zeropadding2d_26\n",
      "lrn2d_9\n",
      "lrn2d_10\n",
      "zeropadding2d_25\n",
      "zeropadding2d_27\n",
      "conv_4\n",
      "zeropadding2d_28\n",
      "convolution2d_11 - (128, 192, 3, 3)\n",
      "convolution2d_12 - (128, 192, 3, 3)\n",
      "zeropadding2d_29\n",
      "zeropadding2d_31\n",
      "lrn2d_11\n",
      "lrn2d_12\n",
      "zeropadding2d_30\n",
      "zeropadding2d_32\n",
      "conv_5\n",
      "convpool_5\n",
      "flatten\n",
      "dense_1\n",
      "dropout_3\n",
      "dense_2\n",
      "dropout_4\n",
      "dense_3\n",
      "softmax\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import Model\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Flatten, Dense, Dropout, Reshape, Permute, Activation, \\\n",
    "    Input, merge\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from convnetskeras.customlayers import convolution2Dgroup, crosschannelnormalization, \\\n",
    "    splittensor, Softmax4D\n",
    "from customlayers import LRN2D\n",
    "from keras import regularizers\n",
    "# global constants\n",
    "NB_CLASS = 1000         # number of classes\n",
    "LEARNING_RATE = 0.01\n",
    "MOMENTUM = 0.9\n",
    "GAMMA = 0.1\n",
    "DROPOUT = 0.5\n",
    "WEIGHT_DECAY = 0.0005   # L2 regularization factor\n",
    "USE_BN = True           # whether to use batch normalization\n",
    "# Theano - 'th' (channels, width, height)\n",
    "# Tensorflow - 'tf' (width, height, channels)\n",
    "DIM_ORDERING = 'th'\n",
    "def conv2D_bn(x, nb_filter, nb_row, nb_col,\n",
    "              border_mode='same', subsample=(1, 1),\n",
    "              activation='relu', batch_norm=USE_BN,\n",
    "              weight_decay=WEIGHT_DECAY, dim_ordering=DIM_ORDERING):\n",
    "    '''\n",
    "\n",
    "        Info:\n",
    "            Function taken from the Inceptionv3.py script keras github\n",
    "\n",
    "\n",
    "            Utility function to apply to a tensor a module conv + BN\n",
    "            with optional weight decay (L2 weight regularization).\n",
    "    '''\n",
    "    if weight_decay:\n",
    "        W_regularizer = regularizers.l2(weight_decay)\n",
    "        b_regularizer = regularizers.l2(weight_decay)\n",
    "    else:\n",
    "        W_regularizer = None\n",
    "        b_regularizer = None\n",
    "\n",
    "    x = Convolution2D(nb_filter, nb_row, nb_col,\n",
    "                      subsample=subsample,\n",
    "                      activation=activation,\n",
    "                      border_mode=border_mode,\n",
    "                      W_regularizer=W_regularizer,\n",
    "                      b_regularizer=b_regularizer,\n",
    "                      dim_ordering=dim_ordering)(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1), dim_ordering=DIM_ORDERING)(x)\n",
    "\n",
    "    if batch_norm:\n",
    "        x = LRN2D()(x)\n",
    "        x = ZeroPadding2D(padding=(1, 1), dim_ordering=DIM_ORDERING)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "def alexnet2(weights_path=None, nb_class=None):\n",
    "\n",
    "    inputs = Input(shape=(3,227,227))\n",
    "\n",
    "    conv_1 = Convolution2D(96, 11, 11,subsample=(4,4),activation='relu',\n",
    "                           name='conv_1')(inputs)\n",
    "\n",
    "    conv_2 = MaxPooling2D((3, 3), strides=(2,2))(conv_1)\n",
    "    conv_2 = crosschannelnormalization(name=\"convpool_1\")(conv_2)\n",
    "    conv_2 = ZeroPadding2D((2,2))(conv_2)\n",
    "\n",
    "    x1 = conv2D_bn(conv_2, 128, 5, 5, subsample=(1, 1), border_mode='same')\n",
    "    y1 = conv2D_bn(conv_2, 128, 5, 5, subsample=(1, 1), border_mode='same')\n",
    "\n",
    "    conv_2 = merge([x1,y1], mode='concat',concat_axis=1,name=\"conv_2\")\n",
    "\n",
    "    conv_3 = MaxPooling2D((3, 3), strides=(2, 2))(conv_2)\n",
    "    conv_3 = crosschannelnormalization()(conv_3)\n",
    "    conv_3 = ZeroPadding2D((1,1))(conv_3)\n",
    "    conv_3 = Convolution2D(384,3,3,activation='relu',name='conv_3')(conv_3)\n",
    "\n",
    "    conv_4 = ZeroPadding2D((1,1))(conv_3)\n",
    "\n",
    "    x2 = conv2D_bn(conv_4, 192, 3, 3, subsample=(1, 1), border_mode='same')\n",
    "    y2 = conv2D_bn(conv_4, 192, 3, 3, subsample=(1, 1), border_mode='same')\n",
    "\n",
    "    conv_4 = merge([x2,y2], mode='concat',concat_axis=1,name=\"conv_4\")\n",
    "\n",
    "    conv_5 = ZeroPadding2D((1,1))(conv_4)\n",
    "\n",
    "    x3 = conv2D_bn(conv_5, 192, 3, 3, subsample=(1, 1), border_mode='same')\n",
    "    y3 = conv2D_bn(conv_5, 192, 3, 3, subsample=(1, 1), border_mode='same')\n",
    "\n",
    "    conv_5 = merge([x3,y3], mode='concat',concat_axis=1,name=\"conv_5\")\n",
    "\n",
    "    conv_5 = MaxPooling2D((3, 3), strides=(2,2),name=\"convpool_5\")(conv_5)\n",
    "\n",
    "    dense_1 = Flatten(name=\"flatten\")(conv_5)\n",
    "    dense_1 = Dense(4096, activation='relu',name='dense_1')(dense_1)\n",
    "    dense_2 = Dropout(0.5)(dense_1)\n",
    "    dense_2 = Dense(4096, activation='relu',name='dense_2')(dense_2)\n",
    "    dense_3 = Dropout(0.5)(dense_2)\n",
    "    dense_3 = Dense(nb_class,name='dense_3')(dense_3)\n",
    "    prediction = Activation(\"softmax\",name=\"softmax\")(dense_3)\n",
    "\n",
    "\n",
    "    base_model = Model(input=inputs, output=prediction)\n",
    "\n",
    "    if weights_path:\n",
    "        base_model.load_weights(weights_path)\n",
    "\n",
    "    return base_model\n",
    "\n",
    "def load_model(weights_path):\n",
    "\n",
    "    model = alexnet2(weights_path,100)\n",
    "    model.compile(optimizer=\"sgd\", loss='categorical_crossentropy')\n",
    "    return model\n",
    "\n",
    "model = load_model('../dataset/alexnet_weights.h5')\n",
    "for l in model.layers:\n",
    "    if \"convolution2d\"in l.name:\n",
    "        print l.name + \" - \" + str(l.get_weights()[0].shape)\n",
    "    else:\n",
    "        print l.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import keras.backend as K\n",
    "\n",
    "def deconv(model, target_layer, feat_map, im):\n",
    "    dlayers = {}\n",
    "    for l in model.layers:\n",
    "        dlayers[l.name] = l\n",
    "    layerNames = [l.name for l in model.layers]\n",
    "\n",
    "    im = im.reshape((1,) + im.shape)\n",
    "    symX = K.T.tensor4('x')\n",
    "    ##%%%%%%%%%%%%%%%%%%%%%%#\n",
    "    # forward pass\n",
    "    ##%%%%%%%%%%%%%%%%%%%%%%#\n",
    "    X_foward = im\n",
    "    d_switch = {}\n",
    "    layer_index = layerNames.index(target_layer)\n",
    "\n",
    "    for lname in layerNames[:layer_index+1]:\n",
    "        # print('forwarding {} ...'.format(lname))\n",
    "        T_in, T_out = dlayers[lname].input, dlayers[lname].output\n",
    "\n",
    "        forward = K.function([T_in], T_out)\n",
    "        X_foward = forward([X_foward])\n",
    "        # Record the switch variables\n",
    "        if \"convolution2d\" in lname:\n",
    "            d_switch[lname] = np.where(X_foward <= 0)\n",
    "\n",
    "    ##%%%%%%%%%%%%%%%%%%%%%%#\n",
    "    # backward pass\n",
    "    ##%%%%%%%%%%%%%%%%%%%%%%#\n",
    "    X_outlayer = X_foward\n",
    "    # print \"*************Deconvolution*************\"\n",
    "    # print \"Deconvolving %s ...\" % target_layer\n",
    "    if \"maxpooling2d\" in target_layer:\n",
    "        print 'you wanna to see maximal activations in pooling layers?'\n",
    "\n",
    "    elif \"convolution2d\" in target_layer:\n",
    "\n",
    "        output_width, output_height = dlayers[target_layer].output_shape[-2:]\n",
    "        filter_width, filter_height = dlayers[target_layer].W_shape[2], dlayers[target_layer].W_shape[3]\n",
    "\n",
    "        # Compute padding needed\n",
    "        input_width, input_height = X_outlayer.shape[-2:]\n",
    "        pad_width = (output_width - input_width + filter_width - 1) / 2\n",
    "        pad_height = (output_height - input_height + filter_height - 1) / 2\n",
    "        assert isinstance(pad_width, int), \"Pad width size issue at layer %s\" % lname\n",
    "        assert isinstance(pad_height, int), \"Pad height size issue at layer %s\" % lname\n",
    "        \n",
    "        # using switch which recorded from forward pass\n",
    "        X_outlayer[d_switch[target_layer]] = 0\n",
    "        activation = dlayers[target_layer].activation\n",
    "        # relu\n",
    "        X_outlayer = activation(X_outlayer)\n",
    "\n",
    "        # For the first output layer, choose only maxima activation (point) on the feature map\n",
    "        ## Setting other feature maps to zero\n",
    "        list_feat_map = np.arange(X_outlayer.shape[1]).tolist()\n",
    "        list_feat_map.remove(feat_map)\n",
    "        X_outlayer[:, list_feat_map, :, :] = 0\n",
    "\n",
    "        ## Setting other points to zero\n",
    "        for i in range(X_outlayer.shape[0]):\n",
    "            iw, ih = np.unravel_index(X_outlayer[i, feat_map, :, :].argmax(), X_outlayer[i, feat_map, :, :].shape)\n",
    "            maxActivationValue = np.max(X_outlayer[i, feat_map, :, :])\n",
    "            X_outlayer[i, feat_map, :, :] = 0\n",
    "            X_outlayer[i, feat_map, iw, ih] = maxActivationValue\n",
    "\n",
    "        W = dlayers[target_layer].W\n",
    "        W = W.transpose([1,0,2,3])\n",
    "        W = W[:,:, ::-1, ::-1]\n",
    "\n",
    "        conv_out = K.T.nnet.conv2d(input=symX, filters=W, border_mode='valid')\n",
    "        pad = K.function([symX], K.spatial_2d_padding(symX, padding=(pad_width, pad_height), dim_ordering=\"th\"))\n",
    "        X_pad = pad([X_outlayer])\n",
    "\n",
    "        deconv_func = K.function([symX], conv_out)\n",
    "        X_deconv = deconv_func([X_pad])\n",
    "        assert X_deconv.shape[-2:]==(output_width, output_height), \"Deconv output at {} has wrong size\".format(target_layer)\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Invalid layer name {}'.format(target_layer))       \n",
    "\n",
    "    # Iterate remining layers until to input\n",
    "    X_outlayer = X_deconv\n",
    "    for lname in layerNames[:layer_index][::-1]:\n",
    "        # print \"Deconvolving {} ...\".format(lname)\n",
    "        # Unpool\n",
    "        if \"maxpooling2d\" in lname:\n",
    "            p1, p2 = dlayers[lname].pool_size\n",
    "            uppool = K.function([symX], K.resize_images(symX, p1, p2, \"th\"))\n",
    "            X_outlayer = uppool([X_outlayer])\n",
    "        # deconvolution\n",
    "        elif \"convolution2d\" in lname:\n",
    "            output_width, output_height = dlayers[lname].output_shape[-2:]\n",
    "            filter_width = dlayers[lname].W_shape[2]\n",
    "            filter_height = dlayers[lname].W_shape[3]\n",
    "\n",
    "            # Compute padding needed\n",
    "            input_width, input_height = X_outlayer.shape[-2:]\n",
    "            pad_width = (output_width - input_width + filter_width - 1) / 2\n",
    "            pad_height = (output_height - input_height + filter_height - 1) / 2\n",
    "            assert isinstance(pad_width, int), \"Pad width size issue at layer %s\" % lname\n",
    "            assert isinstance(pad_height, int), \"Pad height size issue at layer %s\" % lname\n",
    "\n",
    "            X_outlayer[d_switch[lname]] = 0\n",
    "            activation = dlayers[lname].activation\n",
    "            X_outlayer = activation(X_outlayer)\n",
    "\n",
    "            W = dlayers[lname].W\n",
    "            W = W.transpose([1,0,2,3])\n",
    "            W = W[:,:, ::-1, ::-1]\n",
    "\n",
    "            conv_out = K.T.nnet.conv2d(input=symX, filters=W, border_mode='valid')\n",
    "            pad = K.function([symX], K.spatial_2d_padding(symX, padding=(pad_width, pad_height), dim_ordering=\"th\"))\n",
    "            X_pad = pad([X_outlayer])\n",
    "\n",
    "            deconv_func = K.function([symX], conv_out)\n",
    "            X_deconv = deconv_func([X_pad])\n",
    "            assert X_deconv.shape[-2:]==(output_width, output_height), \"Deconv output at {} has wrong size\".format(lname)\n",
    "            X_outlayer = X_deconv\n",
    "        elif \"padding\" in lname:\n",
    "                pass\n",
    "        else:\n",
    "            raise ValueError(\"Invalid layer name: {}\".format(lname))\n",
    "            \n",
    "    return X_outlayer\n",
    "\n",
    "def loadImage(path):\n",
    "    im = cv2.resize(cv2.imread(imPath), (224, 224)).astype(np.float32)\n",
    "    imOri = im.copy()\n",
    "    im[:,:,0] -= 103.939\n",
    "    im[:,:,1] -= 116.779\n",
    "    im[:,:,2] -= 123.68\n",
    "    im = im.transpose((2,0,1))\n",
    "    return im, imOri\n",
    "\n",
    "def normalize(arg):\n",
    "    arg = arg[0]\n",
    "    minValue = arg.min()\n",
    "    maxValue = arg.max()\n",
    "    imNorm = (arg - minValue) / (maxValue-minValue)\n",
    "    return imNorm.transpose((1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid layer name zeropadding2d_17",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-0544611d2046>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtarget_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mfeat_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_layer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeat_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1b9781bce44a>\u001b[0m in \u001b[0;36mdeconv\u001b[0;34m(model, target_layer, feat_map, im)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid layer name {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_layer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# Iterate remining layers until to input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid layer name zeropadding2d_17"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# choose 4 feature maps to visualize\n",
    "feat_dict = OrderedDict()\n",
    "feat_dict[\"zeropadding2d_17\"] = 1\n",
    "feat_dict[\"zeropadding2d_17\"] = 1\n",
    "\n",
    "# Load data\n",
    "\n",
    "imPath = '../dataset/food10/AisKacang/AisKacang (3).jpg'\n",
    "im, imOri = loadImage(imPath)\n",
    "\n",
    "for k,v in feat_dict.items():\n",
    "    target_layer = k\n",
    "    feat_map = v\n",
    "    output = deconv(model, target_layer, feat_map, im)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(imOri/255.)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(normalize(output))\n",
    "    plt.title(target_layer+\" - \"+str(feat_map))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
