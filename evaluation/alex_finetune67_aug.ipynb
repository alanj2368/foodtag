{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1060 6GB (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5105)\n",
      "/home/machine/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data..\n",
      "(20000,)\n",
      "Data loaded !\n",
      "Test train Shape: \n",
      "(10000, 3, 227, 227)\n",
      "(10000, 3, 227, 227)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:1357: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n",
      "/home/machine/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Fold 1 / 2\n",
      "Weights for \"dense_1\" are loaded\n",
      "Weights for \"dense_2\" are loaded\n",
      "Weights for \"dense_3\" are loaded\n",
      "Extracting features..\n",
      "Deep features extracted  (4096,)\n",
      "\n",
      "Training SVM..\n",
      "SVM acc: : 48.24%\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           AisKacang       0.55      0.67      0.61       100\n",
      "           AngKuKueh       0.23      0.25      0.24       100\n",
      "           ApamBalik       0.51      0.74      0.60       100\n",
      "           Asamlaksa       0.35      0.44      0.39       100\n",
      "              Bahulu       0.79      0.88      0.83       100\n",
      "           Bakkukteh       0.62      0.68      0.65       100\n",
      "      BananaLeafRice       0.57      0.61      0.59       100\n",
      "             Bazhang       0.42      0.45      0.44       100\n",
      "         BeefRendang       0.77      0.89      0.82       100\n",
      "           BingkaUbi       0.57      0.66      0.61       100\n",
      "         Buburchacha       0.44      0.52      0.48       100\n",
      "          Buburpedas       0.56      0.59      0.58       100\n",
      "              Capati       0.35      0.40      0.38       100\n",
      "              Cendol       0.37      0.45      0.40       100\n",
      "         ChaiTowKuay       0.70      0.78      0.74       100\n",
      "        CharKuehTiao       0.65      0.72      0.68       100\n",
      "             CharSiu       0.72      0.73      0.73       100\n",
      "       CheeCheongFun       0.73      0.85      0.79       100\n",
      "           ChiliCrab       0.20      0.26      0.23       100\n",
      "           Chweekueh       0.65      0.69      0.67       100\n",
      "         ClayPotRice       0.28      0.37      0.32       100\n",
      "          CucurUdang       0.43      0.35      0.38       100\n",
      "          CurryLaksa       0.22      0.21      0.22       100\n",
      "           CurryPuff       0.27      0.31      0.29       100\n",
      "               Dodol       0.42      0.52      0.46       100\n",
      "              Durian       0.39      0.43      0.41       100\n",
      "         DurianCrepe       0.36      0.42      0.39       100\n",
      "       FishHeadCurry       0.28      0.28      0.28       100\n",
      "               Guava       0.38      0.39      0.39       100\n",
      "HainaneseChickenRice       0.24      0.32      0.28       100\n",
      "          HokkienMee       0.43      0.38      0.40       100\n",
      "            Huatkuih       0.62      0.60      0.61       100\n",
      "           IkanBakar       0.60      0.56      0.58       100\n",
      "            Kangkung       0.50      0.54      0.52       100\n",
      "           KayaToast       0.37      0.37      0.37       100\n",
      "            Keklapis       0.29      0.37      0.33       100\n",
      "             Ketupat       0.48      0.54      0.51       100\n",
      "           KuihDadar       0.29      0.25      0.27       100\n",
      "           KuihLapis       0.70      0.69      0.70       100\n",
      "        KuihSeriMuka       0.36      0.35      0.36       100\n",
      "             Langsat       0.53      0.51      0.52       100\n",
      "               Lekor       0.38      0.33      0.35       100\n",
      "              Lemang       0.62      0.54      0.58       100\n",
      "         LepatPisang       0.36      0.37      0.36       100\n",
      "              LorMee       0.62      0.67      0.64       100\n",
      "        Maggi goreng       0.83      0.73      0.78       100\n",
      "          Mangosteen       0.43      0.34      0.38       100\n",
      "           MeeGoreng       0.37      0.39      0.38       100\n",
      "         MeeHoonKueh       0.49      0.44      0.47       100\n",
      "         MeeHoonSoup       0.23      0.28      0.25       100\n",
      "             MeeJawa       0.64      0.75      0.69       100\n",
      "            MeeRebus       0.55      0.50      0.52       100\n",
      "            MeeRojak       0.43      0.39      0.41       100\n",
      "             MeeSiam       0.53      0.51      0.52       100\n",
      "            Murtabak       0.62      0.54      0.58       100\n",
      "             Murukku       0.50      0.51      0.50       100\n",
      "   NasiGorengKampung       0.57      0.58      0.58       100\n",
      "           NasiImpit       0.53      0.58      0.56       100\n",
      "          Nasikandar       0.56      0.62      0.59       100\n",
      "           Nasilemak       0.24      0.25      0.25       100\n",
      "         Nasipattaya       0.62      0.55      0.59       100\n",
      "          Ondehondeh       0.43      0.31      0.36       100\n",
      "            Otakotak       0.57      0.62      0.60       100\n",
      "      OysterOmelette       0.54      0.47      0.50       100\n",
      "              PanMee       0.40      0.45      0.42       100\n",
      "       PineappleTart       0.32      0.22      0.26       100\n",
      "        PisangGoreng       0.54      0.54      0.54       100\n",
      "              Popiah       0.54      0.55      0.54       100\n",
      "            PrawnMee       0.37      0.36      0.37       100\n",
      "         Prawnsambal       0.52      0.49      0.50       100\n",
      "                Puri       0.62      0.45      0.52       100\n",
      "           PutuMayam       0.43      0.40      0.41       100\n",
      "          PutuPiring       0.25      0.17      0.20       100\n",
      "            Rambutan       0.44      0.37      0.40       100\n",
      "               Rojak       0.76      0.88      0.81       100\n",
      "           RotiCanai       0.43      0.43      0.43       100\n",
      "            RotiJala       0.51      0.44      0.47       100\n",
      "            RotiJohn       0.55      0.63      0.59       100\n",
      "            RotiNaan       0.39      0.41      0.40       100\n",
      "          RotiTissue       0.32      0.24      0.27       100\n",
      "         SambalPetai       0.59      0.53      0.56       100\n",
      "         SambalUdang       0.36      0.27      0.31       100\n",
      "               Satay       0.52      0.52      0.52       100\n",
      "          Sataycelup       0.45      0.46      0.46       100\n",
      "            SeriMuka       0.89      0.91      0.90       100\n",
      "            SotoAyam       0.46      0.46      0.46       100\n",
      "     TandooriChicken       0.30      0.27      0.29       100\n",
      "            TangYuan       0.50      0.37      0.43       100\n",
      "           TauFooFah       0.66      0.71      0.69       100\n",
      "         TauhuSumbat       0.30      0.24      0.27       100\n",
      "              Thosai       0.51      0.54      0.52       100\n",
      "          TomYumSoup       0.70      0.79      0.74       100\n",
      "               Wajik       0.32      0.22      0.26       100\n",
      "           WanTanMee       0.36      0.29      0.32       100\n",
      "             WaTanHo       0.40      0.34      0.37       100\n",
      "              Wonton       0.46      0.36      0.40       100\n",
      "             YamCake       0.32      0.23      0.27       100\n",
      "           YongTauFu       0.70      0.59      0.64       100\n",
      "             Youtiao       0.41      0.29      0.34       100\n",
      "             Yusheng       0.62      0.53      0.57       100\n",
      "\n",
      "         avg / total       0.48      0.48      0.48     10000\n",
      "\n",
      "Top-1 Accuracy: 49.16%\n",
      "Top-5 Accuracy: 79.65%\n",
      "Generating Barchart..\n",
      "[65 23 69 45 81 64 63 43 88 65 49 58 42 39 75 66 69 83 29 71 34 33 22 32 46\n",
      " 45 43 23 36 34 41 56 60 54 40 33 54 26 73 34 52 36 60 33 67 76 36 39 51 33\n",
      " 76 47 42 47 55 55 57 62 64 32 53 36 66 46 46 23 59 57 43 47 44 42 11 52 87\n",
      " 43 49 66 48 19 51 41 54 48 90 54 29 43 74 24 57 78 24 32 40 43 24 62 30 55]\n",
      "[82 78 90 75 95 95 85 81 94 85 74 94 82 75 87 94 87 94 55 89 70 71 66 71 75\n",
      " 75 76 49 81 68 78 83 82 85 80 81 81 68 94 68 84 66 92 73 91 92 74 72 73 68\n",
      " 89 85 73 81 88 85 82 91 91 62 87 68 92 90 79 81 77 84 72 76 82 80 64 84 98\n",
      " 79 74 87 74 64 82 87 77 77 97 79 59 77 92 79 85 89 61 69 71 77 66 94 68 82]\n",
      "Test train Shape: \n",
      "(10000, 3, 227, 227)\n",
      "(10000, 3, 227, 227)\n",
      "Running Fold 2 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/machine/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"Unable to open object (Object 'dense_1' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0f9ed3f3d841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Running Fold %d / %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0msave_bottleneck67_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malexnet_weights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_svm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mtotal_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_scores\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-0f9ed3f3d841>\u001b[0m in \u001b[0;36msave_bottleneck67_features\u001b[0;34m(X_train, X_test, y_train, y_test, pretrained_weights)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_bottleneck67_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_alexnet_model_finetune67\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malexnet_weights_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_model_weight_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../deep/models/alex_finetune67_aug_weights\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Extracting features..\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbottleneck_features_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/machine/projects/foodtag/visualization/util.pyc\u001b[0m in \u001b[0;36mload_alexnet_model_finetune67\u001b[0;34m(weights_path, nb_class, top_model_weight_path)\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0mweights_file_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtop_model_weight_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m         output=base_model.output)\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/machine/projects/foodtag/visualization/util.pyc\u001b[0m in \u001b[0;36mget_top_model_for_alex_finetune67\u001b[0;34m(nb_class, shape, W_regularizer, weights_file_path, input, output)\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mweights_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m     \u001b[0mweights_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_layer_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dense_1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m     \u001b[0mdense_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4096\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dense_1'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mdense_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdense_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/machine/projects/foodtag/visualization/util.pyc\u001b[0m in \u001b[0;36mget_layer_weights\u001b[0;34m(weights_file, layer_name)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'Weights for \"{}\" are loaded'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (-------src-dir-------/h5py/_objects.c:2582)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (-------src-dir-------/h5py/_objects.c:2541)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/machine/anaconda2/lib/python2.7/site-packages/h5py/_hl/group.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    164\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid HDF5 object reference\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m             \u001b[0moid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_e\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0motype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5i\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (-------src-dir-------/h5py/_objects.c:2582)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper (-------src-dir-------/h5py/_objects.c:2541)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5o.pyx\u001b[0m in \u001b[0;36mh5py.h5o.open (-------src-dir-------/h5py/h5o.c:3551)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Unable to open object (Object 'dense_1' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import config\n",
    "import util\n",
    "\n",
    "fold_count = 1\n",
    "\n",
    "def save_bottleneck67_features(X_train, X_test, y_train, y_test, pretrained_weights):\n",
    "    model = util.load_alexnet_model_finetune67(weights_path=config.alexnet_weights_path, nb_class=config.nb_class, top_model_weight_path=\"../deep/models/alex_finetune67_aug_weights\"+ str(fold_count) +\".h5\")\n",
    "    print \"Extracting features..\"\n",
    "    bottleneck_features_train = model.predict(X_train)\n",
    "    np.save(open('alex_bottleneck67_features_train' + str(fold_count) + '.npy', 'wb'), bottleneck_features_train)\n",
    "\n",
    "    bottleneck_features_validation = model.predict(X_test)\n",
    "    np.save(open('alex_bottleneck67_features_validation' + str(fold_count) + '.npy', 'wb'), bottleneck_features_validation)\n",
    "    print \"Deep features extracted \", bottleneck_features_train.shape[1:]\n",
    "                                               \n",
    "def train_svm(y_train, y_test):\n",
    "    X_train = np.load(open('alex_bottleneck67_features_train' + str(fold_count) + '.npy' , 'rb'))\n",
    "    X_test = np.load(open('alex_bottleneck67_features_validation' + str(fold_count) + '.npy', 'rb'))\n",
    "    \n",
    "    print \"\\nTraining SVM..\"\n",
    "    clf = svm.SVC(kernel='linear', probability=True)\n",
    "    clf.fit(X_train, y_train.ravel())\n",
    "    score = clf.score(X_test, y_test.ravel())\n",
    "    print(\"SVM %s: %.2f%%\" % (\"acc: \", score*100))\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    target_names = ['AisKacang' , 'AngKuKueh' , 'ApamBalik' , 'Asamlaksa' , 'Bahulu' , 'Bakkukteh',\n",
    "     'BananaLeafRice' , 'Bazhang' , 'BeefRendang' , 'BingkaUbi' , 'Buburchacha',\n",
    "     'Buburpedas' , 'Capati' , 'Cendol' , 'ChaiTowKuay' , 'CharKuehTiao' , 'CharSiu',\n",
    "     'CheeCheongFun' , 'ChiliCrab' , 'Chweekueh' , 'ClayPotRice' , 'CucurUdang',\n",
    "     'CurryLaksa' , 'CurryPuff' , 'Dodol' , 'Durian' , 'DurianCrepe' , 'FishHeadCurry',\n",
    "     'Guava' , 'HainaneseChickenRice' , 'HokkienMee' , 'Huatkuih' , 'IkanBakar',\n",
    "     'Kangkung' , 'KayaToast' , 'Keklapis' , 'Ketupat' , 'KuihDadar' , 'KuihLapis',\n",
    "     'KuihSeriMuka' , 'Langsat' , 'Lekor' , 'Lemang' , 'LepatPisang' , 'LorMee',\n",
    "     'Maggi goreng' , 'Mangosteen' , 'MeeGoreng' , 'MeeHoonKueh' , 'MeeHoonSoup',\n",
    "     'MeeJawa' , 'MeeRebus' , 'MeeRojak' , 'MeeSiam' , 'Murtabak' , 'Murukku',\n",
    "     'NasiGorengKampung' , 'NasiImpit' , 'Nasikandar' , 'Nasilemak' , 'Nasipattaya',\n",
    "     'Ondehondeh' , 'Otakotak' , 'OysterOmelette' , 'PanMee' , 'PineappleTart',\n",
    "     'PisangGoreng' , 'Popiah' , 'PrawnMee' , 'Prawnsambal' , 'Puri' , 'PutuMayam',\n",
    "     'PutuPiring' , 'Rambutan' , 'Rojak' , 'RotiCanai' , 'RotiJala' , 'RotiJohn',\n",
    "     'RotiNaan' , 'RotiTissue' , 'SambalPetai' , 'SambalUdang' , 'Satay' , 'Sataycelup',\n",
    "     'SeriMuka' , 'SotoAyam' , 'TandooriChicken' , 'TangYuan' , 'TauFooFah',\n",
    "     'TauhuSumbat' , 'Thosai' , 'TomYumSoup' , 'Wajik' , 'WanTanMee' , 'WaTanHo' , 'Wonton',\n",
    "     'YamCake' , 'YongTauFu' , 'Youtiao' , 'Yusheng']\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    util.plot_confusion_matrix(cm)\n",
    "    #plt.savefig('cm_deep_feaures'+ str(fold_count) +'.png', dpi=300, aspect='auto')\n",
    "    plt.show()\n",
    "    plt.gcf().clear()\n",
    "    f1_score(y_test, y_pred,average=None)\n",
    "    print(classification_report(y_test, y_pred,target_names=target_names))\n",
    "      \n",
    "    #scores = clf.decision_function(X_test)\n",
    "      # Get Top-5\n",
    "    #indices = (-scores).argsort()[:, :5] # take top 5 results\n",
    "    \n",
    "    scores = clf.predict_proba(X_test)\n",
    "    n = 5\n",
    "    indices = np.argsort(scores)[:,:-n-1:-1]\n",
    "    # Get accuracy\n",
    "    top1 = 0.0\n",
    "    top5 = 0.0\n",
    "    correct_predict_top1 = np.zeros((config.nb_class,), dtype=np.int)\n",
    "    correct_predict_top5 = np.zeros((config.nb_class,), dtype=np.int)\n",
    "    \n",
    "    for image_index, index_list in enumerate(indices):\n",
    "        if y_test[image_index] == index_list[0]:\n",
    "            top1 += 1.0\n",
    "        if y_test[image_index] in index_list:\n",
    "            top5 += 1.0\n",
    "    \n",
    "    print('Top-1 Accuracy: ' + str(top1 / len(y_test) * 100.0) + '%')\n",
    "    print('Top-5 Accuracy: ' + str(top5 / len(y_test) * 100.0) + '%')\n",
    "    \n",
    "    print \"Generating Barchart..\"\n",
    "    image_index = None\n",
    "    index_list = None\n",
    "    start_index = 0\n",
    "    end_index = 99\n",
    "    \n",
    "    for class_label in range(0,100):\n",
    "        for image_index in range(start_index,end_index+1):\n",
    "            if y_test[image_index] == indices[image_index][0]:\n",
    "                correct_predict_top1[class_label] += 1\n",
    "            if y_test[image_index] in indices[image_index]:\n",
    "                correct_predict_top5[class_label] += 1\n",
    "        start_index += 100\n",
    "        end_index += 100\n",
    "    \n",
    "    y_pos = np.arange(len(target_names))\n",
    "    performance = correct_predict_top1\n",
    "\n",
    "    rects1 = plt.bar(y_pos, performance)\n",
    "    plt.xticks(y_pos, target_names, rotation='vertical')\n",
    "    plt.ylabel('Total true positive')\n",
    "    plt.title('Total true positive per sample')\n",
    "    \n",
    "    autolabel(rects1)\n",
    "    #plt.savefig('barchart_deep_feaures'+ str(fold_count) +'.png', dpi=300, aspect='auto')\n",
    "    plt.show()\n",
    "    plt.gcf().clear()\n",
    "    \n",
    "    print correct_predict_top1\n",
    "    print correct_predict_top5\n",
    "    \n",
    "\n",
    "\n",
    "    return top1/len(y_test)\n",
    "\n",
    "def autolabel(rects):\n",
    "    # attach some text labels\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                '%d' % int(height),\n",
    "                ha='center', va='bottom')\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    total_scores = 0\n",
    "    print \"Loading data..\"\n",
    "    data, labels, lz = util.load_data()\n",
    "    data = data.astype('float32')\n",
    "    data /= 255\n",
    "    lz = np.array(lz)\n",
    "    print lz.shape\n",
    "    print \"Data loaded !\"\n",
    "    \n",
    "    skf = StratifiedKFold(y=lz, n_folds=config.n_folds, shuffle=False)\n",
    "    \n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        print \"Test train Shape: \"\n",
    "        print data[train].shape\n",
    "        print data[test].shape\n",
    "        print (\"Running Fold %d / %d\" % (i+1, config.n_folds))\n",
    "        \n",
    "        save_bottleneck67_features(data[train], data[test],labels[train], labels[test], config.alexnet_weights_path)\n",
    "        scores = train_svm(labels[train], labels[test])\n",
    "        total_scores = total_scores + scores\n",
    "        fold_count = fold_count + 1\n",
    "        \n",
    "    print(\"Average acc : %.2f%%\" % (total_scores/config.n_folds*100))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
