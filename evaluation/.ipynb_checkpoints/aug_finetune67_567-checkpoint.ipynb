{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1060 6GB (CNMeM is enabled with initial size: 80.0% of memory, cuDNN 5105)\n",
      "/home/machine/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data..\n",
      "(20000,)\n",
      "Data loaded !\n",
      "Test train Shape: \n",
      "(10000, 3, 227, 227)\n",
      "(10000, 3, 227, 227)\n",
      "Running Fold 1 / 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine/anaconda2/lib/python2.7/site-packages/matplotlib/__init__.py:1357: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "load_svm_alex_model() got an unexpected keyword argument 'top_model_weight_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-bfa5eb77e0d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Running Fold %d / %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_folds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0msave_bottleneck67_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malexnet_weights_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_svm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mtotal_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_scores\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-bfa5eb77e0d0>\u001b[0m in \u001b[0;36msave_bottleneck67_features\u001b[0;34m(X_train, X_test, y_train, y_test, pretrained_weights)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msave_bottleneck67_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_svm_alex_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malexnet_weights_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop_model_weight_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../deep/models/alex_finetune67_567_aug_weights\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_count\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\".h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"Extracting features..\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mbottleneck_features_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: load_svm_alex_model() got an unexpected keyword argument 'top_model_weight_path'"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import svm\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import config\n",
    "import util\n",
    "\n",
    "fold_count = 1\n",
    "\n",
    "def save_bottleneck67_features(X_train, X_test, y_train, y_test, pretrained_weights):\n",
    "    model = util.load_svm_alex_model(weights_path=\"../deep/models/alex_finetune67_567_aug_weights\"+ str(fold_count) +\".h5\", nb_class=config.nb_class)\n",
    "    print \"Extracting features..\"\n",
    "    bottleneck_features_train = model.predict(X_train)\n",
    "    np.save(open('alex_bottleneck67_features_train' + str(fold_count) + '.npy', 'wb'), bottleneck_features_train)\n",
    "\n",
    "    bottleneck_features_validation = model.predict(X_test)\n",
    "    np.save(open('alex_bottleneck67_features_validation' + str(fold_count) + '.npy', 'wb'), bottleneck_features_validation)\n",
    "    print \"Deep features extracted \", bottleneck_features_train.shape[1:]\n",
    "                                               \n",
    "def train_svm(y_train, y_test):\n",
    "    X_train = np.load(open('alex_bottleneck67_features_train' + str(fold_count) + '.npy' , 'rb'))\n",
    "    X_test = np.load(open('alex_bottleneck67_features_validation' + str(fold_count) + '.npy', 'rb'))\n",
    "    \n",
    "    print \"\\nTraining SVM..\"\n",
    "    clf = svm.SVC(kernel='linear', probability=True)\n",
    "    clf.fit(X_train, y_train.ravel())\n",
    "    score = clf.score(X_test, y_test.ravel())\n",
    "    print(\"SVM %s: %.2f%%\" % (\"acc: \", score*100))\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    target_names = ['AisKacang' , 'AngKuKueh' , 'ApamBalik' , 'Asamlaksa' , 'Bahulu' , 'Bakkukteh',\n",
    "     'BananaLeafRice' , 'Bazhang' , 'BeefRendang' , 'BingkaUbi' , 'Buburchacha',\n",
    "     'Buburpedas' , 'Capati' , 'Cendol' , 'ChaiTowKuay' , 'CharKuehTiao' , 'CharSiu',\n",
    "     'CheeCheongFun' , 'ChiliCrab' , 'Chweekueh' , 'ClayPotRice' , 'CucurUdang',\n",
    "     'CurryLaksa' , 'CurryPuff' , 'Dodol' , 'Durian' , 'DurianCrepe' , 'FishHeadCurry',\n",
    "     'Guava' , 'HainaneseChickenRice' , 'HokkienMee' , 'Huatkuih' , 'IkanBakar',\n",
    "     'Kangkung' , 'KayaToast' , 'Keklapis' , 'Ketupat' , 'KuihDadar' , 'KuihLapis',\n",
    "     'KuihSeriMuka' , 'Langsat' , 'Lekor' , 'Lemang' , 'LepatPisang' , 'LorMee',\n",
    "     'Maggi goreng' , 'Mangosteen' , 'MeeGoreng' , 'MeeHoonKueh' , 'MeeHoonSoup',\n",
    "     'MeeJawa' , 'MeeRebus' , 'MeeRojak' , 'MeeSiam' , 'Murtabak' , 'Murukku',\n",
    "     'NasiGorengKampung' , 'NasiImpit' , 'Nasikandar' , 'Nasilemak' , 'Nasipattaya',\n",
    "     'Ondehondeh' , 'Otakotak' , 'OysterOmelette' , 'PanMee' , 'PineappleTart',\n",
    "     'PisangGoreng' , 'Popiah' , 'PrawnMee' , 'Prawnsambal' , 'Puri' , 'PutuMayam',\n",
    "     'PutuPiring' , 'Rambutan' , 'Rojak' , 'RotiCanai' , 'RotiJala' , 'RotiJohn',\n",
    "     'RotiNaan' , 'RotiTissue' , 'SambalPetai' , 'SambalUdang' , 'Satay' , 'Sataycelup',\n",
    "     'SeriMuka' , 'SotoAyam' , 'TandooriChicken' , 'TangYuan' , 'TauFooFah',\n",
    "     'TauhuSumbat' , 'Thosai' , 'TomYumSoup' , 'Wajik' , 'WanTanMee' , 'WaTanHo' , 'Wonton',\n",
    "     'YamCake' , 'YongTauFu' , 'Youtiao' , 'Yusheng']\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    util.plot_confusion_matrix(cm)\n",
    "    #plt.savefig('cm_deep_feaures'+ str(fold_count) +'.png', dpi=300, aspect='auto')\n",
    "    plt.show()\n",
    "    plt.gcf().clear()\n",
    "    f1_score(y_test, y_pred,average=None)\n",
    "    print(classification_report(y_test, y_pred,target_names=target_names))\n",
    "      \n",
    "    #scores = clf.decision_function(X_test)\n",
    "      # Get Top-5\n",
    "    #indices = (-scores).argsort()[:, :5] # take top 5 results\n",
    "    \n",
    "    scores = clf.predict_proba(X_test)\n",
    "    n = 5\n",
    "    indices = np.argsort(scores)[:,:-n-1:-1]\n",
    "    # Get accuracy\n",
    "    top1 = 0.0\n",
    "    top5 = 0.0\n",
    "    correct_predict_top1 = np.zeros((config.nb_class,), dtype=np.int)\n",
    "    correct_predict_top5 = np.zeros((config.nb_class,), dtype=np.int)\n",
    "    \n",
    "    for image_index, index_list in enumerate(indices):\n",
    "        if y_test[image_index] == index_list[0]:\n",
    "            top1 += 1.0\n",
    "        if y_test[image_index] in index_list:\n",
    "            top5 += 1.0\n",
    "    \n",
    "    print('Top-1 Accuracy: ' + str(top1 / len(y_test) * 100.0) + '%')\n",
    "    print('Top-5 Accuracy: ' + str(top5 / len(y_test) * 100.0) + '%')\n",
    "    \n",
    "    print \"Generating Barchart..\"\n",
    "    image_index = None\n",
    "    index_list = None\n",
    "    start_index = 0\n",
    "    end_index = 99\n",
    "    \n",
    "    for class_label in range(0,100):\n",
    "        for image_index in range(start_index,end_index+1):\n",
    "            if y_test[image_index] == indices[image_index][0]:\n",
    "                correct_predict_top1[class_label] += 1\n",
    "            if y_test[image_index] in indices[image_index]:\n",
    "                correct_predict_top5[class_label] += 1\n",
    "        start_index += 100\n",
    "        end_index += 100\n",
    "    \n",
    "    y_pos = np.arange(len(target_names))\n",
    "    performance = correct_predict_top1\n",
    "\n",
    "    rects1 = plt.bar(y_pos, performance)\n",
    "    plt.xticks(y_pos, target_names, rotation='vertical')\n",
    "    plt.ylabel('Total true positive')\n",
    "    plt.title('Total true positive per sample')\n",
    "    \n",
    "    autolabel(rects1)\n",
    "    #plt.savefig('barchart_deep_feaures'+ str(fold_count) +'.png', dpi=300, aspect='auto')\n",
    "    plt.show()\n",
    "    plt.gcf().clear()\n",
    "    \n",
    "    print correct_predict_top1\n",
    "    print correct_predict_top5\n",
    "    \n",
    "\n",
    "\n",
    "    return top1/len(y_test)\n",
    "\n",
    "def autolabel(rects):\n",
    "    # attach some text labels\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        plt.text(rect.get_x() + rect.get_width()/2., 1.05*height,\n",
    "                '%d' % int(height),\n",
    "                ha='center', va='bottom')\n",
    " \n",
    "if __name__ == \"__main__\":\n",
    "    total_scores = 0\n",
    "    print \"Loading data..\"\n",
    "    data, labels, lz = util.load_data()\n",
    "    data = data.astype('float32')\n",
    "    data /= 255\n",
    "    lz = np.array(lz)\n",
    "    print lz.shape\n",
    "    print \"Data loaded !\"\n",
    "    \n",
    "    skf = StratifiedKFold(y=lz, n_folds=config.n_folds, shuffle=False)\n",
    "    \n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        print \"Test train Shape: \"\n",
    "        print data[train].shape\n",
    "        print data[test].shape\n",
    "        print (\"Running Fold %d / %d\" % (i+1, config.n_folds))\n",
    "        \n",
    "        save_bottleneck67_features(data[train], data[test],labels[train], labels[test], config.alexnet_weights_path)\n",
    "        scores = train_svm(labels[train], labels[test])\n",
    "        total_scores = total_scores + scores\n",
    "        fold_count = fold_count + 1\n",
    "        \n",
    "    print(\"Average acc : %.2f%%\" % (total_scores/config.n_folds*100))\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
