{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data..\n",
      "Data loaded !\n",
      "Running Fold 1 / 2\n",
      "Training CNN..\n",
      "Train on 400 samples, validate on 400 samples\n",
      "Epoch 1/250\n",
      "400/400 [==============================] - 50s - loss: 3.8347 - acc: 0.2300 - val_loss: 2.0063 - val_acc: 0.2500\n",
      "Epoch 2/250\n",
      "400/400 [==============================] - 49s - loss: 2.1887 - acc: 0.2775 - val_loss: 1.7126 - val_acc: 0.2500\n",
      "Epoch 3/250\n",
      " 64/400 [===>..........................] - ETA: 30s - loss: 2.0274 - acc: 0.3281"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Model Name:\n",
    "        AlexNet - using the Functional Keras API\n",
    "        Replicated from the Caffe Zoo Model Version.\n",
    "    Paper:\n",
    "         ImageNet classification with deep convolutional neural networks by Krizhevsky et al. in NIPS 2012\n",
    "    Alternative Example:\n",
    "        Available at: http://caffe.berkeleyvision.org/model_zoo.html\n",
    "        https://github.com/uoguelph-mlrg/theano_alexnet/tree/master/pretrained/alexnet\n",
    "    Original Dataset:\n",
    "        ILSVRC 2012\n",
    "\"\"\"\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from KerasLayers.Custom_layers import LRN2D\n",
    "from keras.optimizers import SGD,RMSprop\n",
    "\n",
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import hickle as hkl\n",
    "import numpy as np\n",
    "\n",
    "# global constants\n",
    "NB_CLASS = 10       # number of classes\n",
    "LEARNING_RATE = 0.0001\n",
    "MOMENTUM = 0.9\n",
    "ALPHA = 0.0001\n",
    "BETA = 0.75\n",
    "GAMMA = 0.1\n",
    "DROPOUT = 0.5\n",
    "WEIGHT_DECAY = 0.0005\n",
    "LRN2D_norm = True       # whether to use batch normalization\n",
    "# Theano - 'th' (channels, width, height)\n",
    "# Tensorflow - 'tf' (width, height, channels)\n",
    "DIM_ORDERING = 'th'\n",
    "\n",
    "\n",
    "def conv2D_lrn2d(x, nb_filter, nb_row, nb_col,\n",
    "                 border_mode='same', subsample=(1, 1),\n",
    "                 activation='relu', LRN2D_norm=True,\n",
    "                 weight_decay=WEIGHT_DECAY, dim_ordering=DIM_ORDERING):\n",
    "    '''\n",
    "        Info:\n",
    "            Function taken from the Inceptionv3.py script keras github\n",
    "            Utility function to apply to a tensor a module Convolution + lrn2d\n",
    "            with optional weight decay (L2 weight regularization).\n",
    "    '''\n",
    "    if weight_decay:\n",
    "        W_regularizer = regularizers.l2(weight_decay)\n",
    "        b_regularizer = regularizers.l2(weight_decay)\n",
    "    else:\n",
    "        W_regularizer = None\n",
    "        b_regularizer = None\n",
    "\n",
    "    x = Convolution2D(nb_filter, nb_row, nb_col,\n",
    "                      subsample=subsample,\n",
    "                      activation=activation,\n",
    "                      border_mode=border_mode,\n",
    "                      W_regularizer=W_regularizer,\n",
    "                      b_regularizer=b_regularizer,\n",
    "                      bias=False,\n",
    "                      dim_ordering=dim_ordering)(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1), dim_ordering=DIM_ORDERING)(x)\n",
    "\n",
    "    if LRN2D_norm:\n",
    "\n",
    "        x = LRN2D(alpha=ALPHA, beta=BETA)(x)\n",
    "        x = ZeroPadding2D(padding=(1, 1), dim_ordering=DIM_ORDERING)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def create_model(weights_path=None):\n",
    "    # Define image input layer\n",
    "    if DIM_ORDERING == 'th':\n",
    "        INP_SHAPE = (3, 224, 224)  # 3 - Number of RGB Colours\n",
    "        img_input = Input(shape=INP_SHAPE)\n",
    "        CONCAT_AXIS = 1\n",
    "    elif DIM_ORDERING == 'tf':\n",
    "        INP_SHAPE = (224, 224, 3)  # 3 - Number of RGB Colours\n",
    "        img_input = Input(shape=INP_SHAPE)\n",
    "        CONCAT_AXIS = 3\n",
    "    else:\n",
    "        raise Exception('Invalid dim ordering: ' + str(DIM_ORDERING))\n",
    "\n",
    "    # Channel 1 - Convolution Net Layer 1\n",
    "    x = conv2D_lrn2d(\n",
    "        img_input, 3, 11, 11, subsample=(\n",
    "            1, 1), border_mode='same')\n",
    "    x = MaxPooling2D(\n",
    "        strides=(\n",
    "            4, 4), pool_size=(\n",
    "                4, 4), dim_ordering=DIM_ORDERING)(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1), dim_ordering=DIM_ORDERING)(x)\n",
    "\n",
    "    # Channel 1 - Convolution Net Layer 2\n",
    "    x = conv2D_lrn2d(x, 48, 55, 55, subsample=(1, 1), border_mode='same')\n",
    "    x = MaxPooling2D(\n",
    "        strides=(\n",
    "            2, 2), pool_size=(\n",
    "                2, 2), dim_ordering=DIM_ORDERING)(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1), dim_ordering=DIM_ORDERING)(x)\n",
    "\n",
    "    # Channel 1 - Convolution Net Layer 3\n",
    "    x = conv2D_lrn2d(x, 128, 27, 27, subsample=(1, 1), border_mode='same')\n",
    "    x = MaxPooling2D(\n",
    "        strides=(\n",
    "            2, 2), pool_size=(\n",
    "                2, 2), dim_ordering=DIM_ORDERING)(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1), dim_ordering=DIM_ORDERING)(x)\n",
    "\n",
    "    # Channel 1 - Convolution Net Layer 4\n",
    "    x = conv2D_lrn2d(x, 192, 13, 13, subsample=(1, 1), border_mode='same')\n",
    "    x = ZeroPadding2D(padding=(1, 1), dim_ordering=DIM_ORDERING)(x)\n",
    "\n",
    "    # Channel 1 - Convolution Net Layer 5\n",
    "    x = conv2D_lrn2d(x, 192, 13, 13, subsample=(1, 1), border_mode='same')\n",
    "    x = ZeroPadding2D(padding=(1, 1), dim_ordering=DIM_ORDERING)(x)\n",
    "\n",
    "    # Channel 1 - Cov Net Layer 6\n",
    "    x = conv2D_lrn2d(x, 128, 27, 27, subsample=(1, 1), border_mode='same')\n",
    "    x = MaxPooling2D(\n",
    "        strides=(\n",
    "            2, 2), pool_size=(\n",
    "                2, 2), dim_ordering=DIM_ORDERING)(x)\n",
    "    x = ZeroPadding2D(padding=(1, 1), dim_ordering=DIM_ORDERING)(x)\n",
    "\n",
    "    # Channel 1 - Cov Net Layer 7\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    x = Dropout(DROPOUT)(x)\n",
    "\n",
    "    # Channel 1 - Cov Net Layer 8\n",
    "    x = Dense(2048, activation='relu')(x)\n",
    "    x = Dropout(DROPOUT)(x)\n",
    "\n",
    "    # Final Channel - Cov Net 9\n",
    "    prediction = Dense(output_dim=NB_CLASS,\n",
    "              activation='softmax')(x)\n",
    "\n",
    "    if weights_path:\n",
    "        x.load_weights(weights_path)\n",
    "\n",
    "    model = Model(input=img_input,\n",
    "                  output=prediction)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def check_print():\n",
    "    # Create the Model\n",
    "    x, img_input, CONCAT_AXIS, INP_SHAPE, DIM_ORDERING = create_model()\n",
    "\n",
    "    # Create a Keras Model - Functional API\n",
    "    model = Model(input=img_input,\n",
    "                  output=[x])\n",
    "    model.summary()\n",
    "\n",
    "    # Save a PNG of the Model Build\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='categorical_crossentropy')\n",
    "    print \"Check print\"\n",
    "\n",
    "def load_data():\n",
    "    # load your data using this function\n",
    "    d = hkl.load('../dataset/myfood4-224.hkl')\n",
    "    data = d['trainFeatures']\n",
    "    labels = d['trainLabels']\n",
    "    lz = d['labels']\n",
    "    data = data.reshape(data.shape[0], 3, 224, 224)\n",
    "    #data = data.transpose(0, 2, 3, 1)\n",
    "\n",
    "    return data,labels,lz\n",
    "\n",
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    opt = SGD(lr=0.1)\n",
    "    model.compile(loss = \"categorical_crossentropy\", optimizer = opt, metrics=['accuracy'])\n",
    "    #rms = RMSprop(lr=5e-4, rho=0.9, epsilon=1e-08, decay=0.01)\n",
    "    #model.compile(optimizer=rms, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    Y_train = np_utils.to_categorical(y_train, NB_CLASS)\n",
    "    Y_test = np_utils.to_categorical(y_test, NB_CLASS)\n",
    "\n",
    "    print \"Training CNN..\"\n",
    "    hist = model.fit(X_train, Y_train, nb_epoch=250, validation_data=(X_test, Y_test),batch_size=32,verbose=1)\n",
    "    #visualize_loss(hist)\n",
    "    model.save_weights(\"food10x_scratch_weights.h5\")\n",
    "\n",
    "    scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "    print(\"Softmax %s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    return scores\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_folds = 2\n",
    "    cvscores = []\n",
    "    print \"Loading data..\"\n",
    "    data, labels, lz = load_data()\n",
    "    print \"Data loaded !\"\n",
    "    data = data.astype('float32')\n",
    "    data /= 255\n",
    "    lz = np.array(lz)\n",
    "    total_scores = 0\n",
    "\n",
    "\n",
    "    skf = StratifiedKFold(y=lz, n_folds=n_folds, shuffle=False)\n",
    "\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        print (\"Running Fold %d / %d\" % (i+1, n_folds))\n",
    "        model = None # Clearing the NN.\n",
    "        #model = create_model(weights_path=None, heatmap=False)\n",
    "        model = create_model(weights_path=None)\n",
    "        scores = train_and_evaluate_model(model, data[train], labels[train], data[test], labels[test])\n",
    "        #print \"Score for fold \", i+1, \"= \", scores*100\n",
    "        total_scores = total_scores + scores\n",
    "\n",
    "    print(\"Average acc : %.2f%%\" % (total_scores/n_folds*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
