{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX 1060 6GB (CNMeM is disabled, cuDNN 5105)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data..\n",
      "Data loaded !"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/machine/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'ds' parameter is not going to exist anymore as it is going to be replaced by the parameter 'ws'.\n",
      "  mode='max')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fine-tuning CNN..\n",
      "Epoch 1/400\n",
      "15000/15000 [==============================] - 31s - loss: 4.7906 - acc: 0.0131    \n",
      "Epoch 2/400\n",
      "15000/15000 [==============================] - 31s - loss: 4.5654 - acc: 0.0258    \n",
      "Epoch 3/400\n",
      "15000/15000 [==============================] - 31s - loss: 4.4512 - acc: 0.0369    \n",
      "Epoch 4/400\n",
      "15000/15000 [==============================] - 31s - loss: 4.3535 - acc: 0.0500    \n",
      "Epoch 5/400\n",
      "15000/15000 [==============================] - 31s - loss: 4.2702 - acc: 0.0653    \n",
      "Epoch 6/400\n",
      "15000/15000 [==============================] - 31s - loss: 4.1771 - acc: 0.0811    \n",
      "Epoch 7/400\n",
      "15000/15000 [==============================] - 31s - loss: 4.1017 - acc: 0.0901    \n",
      "Epoch 8/400\n",
      "15000/15000 [==============================] - 31s - loss: 4.0152 - acc: 0.0980    \n",
      "Epoch 9/400\n",
      "15000/15000 [==============================] - 32s - loss: 3.9477 - acc: 0.1095    \n",
      "Epoch 10/400\n",
      "15000/15000 [==============================] - 31s - loss: 3.8567 - acc: 0.1241    \n",
      "Epoch 11/400\n",
      "15000/15000 [==============================] - 31s - loss: 3.7979 - acc: 0.1286    \n",
      "Epoch 12/400\n",
      "15000/15000 [==============================] - 32s - loss: 3.7343 - acc: 0.1422    \n",
      "Epoch 13/400\n",
      "15000/15000 [==============================] - 32s - loss: 3.6724 - acc: 0.1502    \n",
      "Epoch 14/400\n",
      "15000/15000 [==============================] - 31s - loss: 3.6063 - acc: 0.1616    \n",
      "Epoch 15/400\n",
      "15000/15000 [==============================] - 32s - loss: 3.5681 - acc: 0.1661    \n",
      "Epoch 16/400\n",
      "15000/15000 [==============================] - 31s - loss: 3.5051 - acc: 0.1772    \n",
      "Epoch 17/400\n",
      "15000/15000 [==============================] - 32s - loss: 3.4593 - acc: 0.1813    \n",
      "Epoch 18/400\n",
      "15000/15000 [==============================] - 32s - loss: 3.4015 - acc: 0.1971    \n",
      "Epoch 19/400\n",
      "15000/15000 [==============================] - 32s - loss: 3.3471 - acc: 0.2075    \n",
      "Epoch 20/400\n",
      "15000/15000 [==============================] - 32s - loss: 3.3103 - acc: 0.2101    \n",
      "Epoch 21/400\n",
      "15000/15000 [==============================] - 31s - loss: 3.2590 - acc: 0.2179    \n",
      "Epoch 22/400\n",
      "15000/15000 [==============================] - 32s - loss: 3.2137 - acc: 0.2297    \n",
      "Epoch 23/400\n",
      "15000/15000 [==============================] - 32s - loss: 3.1734 - acc: 0.2381    \n",
      "Epoch 24/400\n",
      "15000/15000 [==============================] - 31s - loss: 3.1240 - acc: 0.2504    \n",
      "Epoch 25/400\n",
      "15000/15000 [==============================] - 32s - loss: 3.0883 - acc: 0.2501    \n",
      "Epoch 26/400\n",
      "15000/15000 [==============================] - 32s - loss: 3.0546 - acc: 0.2597    \n",
      "Epoch 27/400\n",
      "15000/15000 [==============================] - 32s - loss: 3.0209 - acc: 0.2656    \n",
      "Epoch 28/400\n",
      "15000/15000 [==============================] - 31s - loss: 2.9843 - acc: 0.2733    \n",
      "Epoch 29/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.9355 - acc: 0.2825    \n",
      "Epoch 30/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.9091 - acc: 0.2871    \n",
      "Epoch 31/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.8755 - acc: 0.2955    \n",
      "Epoch 32/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.8479 - acc: 0.2987    \n",
      "Epoch 33/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.8140 - acc: 0.3055    \n",
      "Epoch 34/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.7846 - acc: 0.3053    \n",
      "Epoch 35/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.7537 - acc: 0.3183    \n",
      "Epoch 36/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.7273 - acc: 0.3251    \n",
      "Epoch 37/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.6831 - acc: 0.3271    \n",
      "Epoch 38/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.6654 - acc: 0.3385    \n",
      "Epoch 39/400\n",
      "15000/15000 [==============================] - 31s - loss: 2.6367 - acc: 0.3415    \n",
      "Epoch 40/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.6005 - acc: 0.3480    \n",
      "Epoch 41/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.5777 - acc: 0.3545    \n",
      "Epoch 42/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.5484 - acc: 0.3656    \n",
      "Epoch 43/400\n",
      "15000/15000 [==============================] - 31s - loss: 2.5263 - acc: 0.3647    \n",
      "Epoch 44/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.4971 - acc: 0.3711    \n",
      "Epoch 45/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.4606 - acc: 0.3807    \n",
      "Epoch 46/400\n",
      "15000/15000 [==============================] - 31s - loss: 2.4467 - acc: 0.3804    \n",
      "Epoch 47/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.4148 - acc: 0.3893    \n",
      "Epoch 48/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.3918 - acc: 0.3923    \n",
      "Epoch 49/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.3564 - acc: 0.4043    \n",
      "Epoch 50/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.3327 - acc: 0.4067    \n",
      "Epoch 51/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.3104 - acc: 0.4115    \n",
      "Epoch 52/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.2794 - acc: 0.4241    \n",
      "Epoch 53/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.2603 - acc: 0.4209    \n",
      "Epoch 54/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.2429 - acc: 0.4261    \n",
      "Epoch 55/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.2217 - acc: 0.4361    \n",
      "Epoch 56/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.1997 - acc: 0.4360    \n",
      "Epoch 57/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.1866 - acc: 0.4345    \n",
      "Epoch 58/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.1592 - acc: 0.4491    \n",
      "Epoch 59/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.1320 - acc: 0.4547    \n",
      "Epoch 60/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.1037 - acc: 0.4604    \n",
      "Epoch 61/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.0942 - acc: 0.4647    \n",
      "Epoch 62/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.0668 - acc: 0.4649    \n",
      "Epoch 63/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.0422 - acc: 0.4777    \n",
      "Epoch 64/400\n",
      "15000/15000 [==============================] - 32s - loss: 2.0232 - acc: 0.4793    \n",
      "Epoch 65/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.9989 - acc: 0.4835    \n",
      "Epoch 66/400\n",
      "15000/15000 [==============================] - 31s - loss: 1.9850 - acc: 0.4900    \n",
      "Epoch 67/400\n",
      "15000/15000 [==============================] - 31s - loss: 1.9668 - acc: 0.4917    \n",
      "Epoch 68/400\n",
      "15000/15000 [==============================] - 31s - loss: 1.9475 - acc: 0.4974    \n",
      "Epoch 69/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.9194 - acc: 0.5014    \n",
      "Epoch 70/400\n",
      "15000/15000 [==============================] - 31s - loss: 1.9041 - acc: 0.5048    \n",
      "Epoch 71/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.8876 - acc: 0.5073    \n",
      "Epoch 72/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.8657 - acc: 0.5193    \n",
      "Epoch 73/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.8454 - acc: 0.5193    \n",
      "Epoch 74/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.8281 - acc: 0.5241    \n",
      "Epoch 75/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.8109 - acc: 0.5271    \n",
      "Epoch 76/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.7997 - acc: 0.5301    \n",
      "Epoch 77/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.7680 - acc: 0.5415    \n",
      "Epoch 78/400\n",
      "15000/15000 [==============================] - 31s - loss: 1.7518 - acc: 0.5457    \n",
      "Epoch 79/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.7226 - acc: 0.5531    \n",
      "Epoch 80/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.7252 - acc: 0.5545    \n",
      "Epoch 81/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.7034 - acc: 0.5581    \n",
      "Epoch 82/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.6765 - acc: 0.5664    \n",
      "Epoch 83/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.6660 - acc: 0.5660    \n",
      "Epoch 84/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.6540 - acc: 0.5716    \n",
      "Epoch 85/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.6354 - acc: 0.5731    \n",
      "Epoch 86/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.6158 - acc: 0.5819    \n",
      "Epoch 87/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.6009 - acc: 0.5805    \n",
      "Epoch 88/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.5800 - acc: 0.5838    \n",
      "Epoch 89/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.5740 - acc: 0.5890    \n",
      "Epoch 90/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.5535 - acc: 0.5974    \n",
      "Epoch 91/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.5359 - acc: 0.5960    \n",
      "Epoch 92/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.5216 - acc: 0.6023    \n",
      "Epoch 93/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.5050 - acc: 0.6057    \n",
      "Epoch 94/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.4867 - acc: 0.6162    \n",
      "Epoch 95/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.4787 - acc: 0.6130    \n",
      "Epoch 96/400\n",
      "15000/15000 [==============================] - 31s - loss: 1.4712 - acc: 0.6219    \n",
      "Epoch 97/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.4502 - acc: 0.6209    \n",
      "Epoch 98/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.4284 - acc: 0.6287    \n",
      "Epoch 99/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.4113 - acc: 0.6332    \n",
      "Epoch 100/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.3966 - acc: 0.6325    \n",
      "Epoch 101/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.3900 - acc: 0.6391    \n",
      "Epoch 102/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.3745 - acc: 0.6426    \n",
      "Epoch 103/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.3611 - acc: 0.6428    \n",
      "Epoch 104/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.3416 - acc: 0.6523    \n",
      "Epoch 105/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.3267 - acc: 0.6537    \n",
      "Epoch 106/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.3153 - acc: 0.6586    \n",
      "Epoch 107/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.3091 - acc: 0.6551    \n",
      "Epoch 108/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.2849 - acc: 0.6620    \n",
      "Epoch 109/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.2672 - acc: 0.6728    \n",
      "Epoch 110/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.2645 - acc: 0.6677    \n",
      "Epoch 111/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.2454 - acc: 0.6801    \n",
      "Epoch 112/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.2402 - acc: 0.6804    \n",
      "Epoch 113/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.2234 - acc: 0.6833    \n",
      "Epoch 114/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.2074 - acc: 0.6913    \n",
      "Epoch 115/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.1963 - acc: 0.6881    \n",
      "Epoch 116/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.1855 - acc: 0.6905    \n",
      "Epoch 117/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.1683 - acc: 0.6997    \n",
      "Epoch 118/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.1537 - acc: 0.7012    \n",
      "Epoch 119/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.1493 - acc: 0.7022    \n",
      "Epoch 120/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.1283 - acc: 0.7103    \n",
      "Epoch 121/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.1253 - acc: 0.7078    \n",
      "Epoch 122/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.1085 - acc: 0.7161    \n",
      "Epoch 123/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.0951 - acc: 0.7187    \n",
      "Epoch 124/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.0936 - acc: 0.7154    \n",
      "Epoch 125/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.0798 - acc: 0.7240    \n",
      "Epoch 126/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.0624 - acc: 0.7280    \n",
      "Epoch 127/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.0557 - acc: 0.7295    \n",
      "Epoch 128/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.0529 - acc: 0.7237    \n",
      "Epoch 129/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.0433 - acc: 0.7358    \n",
      "Epoch 130/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.0353 - acc: 0.7291    \n",
      "Epoch 131/400\n",
      "15000/15000 [==============================] - 32s - loss: 1.0101 - acc: 0.7410    \n",
      "Epoch 132/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.9903 - acc: 0.7480    \n",
      "Epoch 133/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.9905 - acc: 0.7447    \n",
      "Epoch 134/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.9783 - acc: 0.7492    \n",
      "Epoch 135/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.9789 - acc: 0.7504    \n",
      "Epoch 136/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.9654 - acc: 0.7569    \n",
      "Epoch 137/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.9540 - acc: 0.7568    \n",
      "Epoch 138/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.9346 - acc: 0.7611    \n",
      "Epoch 139/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.9235 - acc: 0.7671    \n",
      "Epoch 140/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.9159 - acc: 0.7682    \n",
      "Epoch 141/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.9120 - acc: 0.7679    \n",
      "Epoch 142/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.9011 - acc: 0.7743    \n",
      "Epoch 143/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.8873 - acc: 0.7765    \n",
      "Epoch 144/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.8808 - acc: 0.7763    \n",
      "Epoch 145/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.8690 - acc: 0.7805    \n",
      "Epoch 146/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.8647 - acc: 0.7834    \n",
      "Epoch 147/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.8580 - acc: 0.7844    \n",
      "Epoch 148/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.8502 - acc: 0.7871    \n",
      "Epoch 149/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.8498 - acc: 0.7878    \n",
      "Epoch 150/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.8323 - acc: 0.7931    \n",
      "Epoch 151/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.8168 - acc: 0.7954    \n",
      "Epoch 152/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.8156 - acc: 0.7993    \n",
      "Epoch 153/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.8090 - acc: 0.7976    \n",
      "Epoch 154/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.7847 - acc: 0.8055    \n",
      "Epoch 155/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.7845 - acc: 0.8065    \n",
      "Epoch 156/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.7763 - acc: 0.8073    \n",
      "Epoch 157/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.7650 - acc: 0.8092    \n",
      "Epoch 158/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.7540 - acc: 0.8157    \n",
      "Epoch 159/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.7568 - acc: 0.8159    \n",
      "Epoch 160/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.7476 - acc: 0.8165    \n",
      "Epoch 161/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.7429 - acc: 0.8217    \n",
      "Epoch 162/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.7339 - acc: 0.8187    \n",
      "Epoch 163/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.7277 - acc: 0.8250    \n",
      "Epoch 164/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.7177 - acc: 0.8275    \n",
      "Epoch 165/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.7161 - acc: 0.8250    \n",
      "Epoch 166/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.7008 - acc: 0.8284    \n",
      "Epoch 167/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6963 - acc: 0.8313    \n",
      "Epoch 168/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6839 - acc: 0.8334    \n",
      "Epoch 169/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6828 - acc: 0.8346    \n",
      "Epoch 170/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6734 - acc: 0.8352    \n",
      "Epoch 171/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6742 - acc: 0.8351    \n",
      "Epoch 172/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6575 - acc: 0.8415    \n",
      "Epoch 173/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6505 - acc: 0.8444    \n",
      "Epoch 174/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6472 - acc: 0.8455    \n",
      "Epoch 175/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6435 - acc: 0.8469    \n",
      "Epoch 176/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6359 - acc: 0.8477    \n",
      "Epoch 177/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6265 - acc: 0.8508    \n",
      "Epoch 178/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6201 - acc: 0.8550    \n",
      "Epoch 179/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6156 - acc: 0.8533    \n",
      "Epoch 180/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6036 - acc: 0.8575    \n",
      "Epoch 181/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.6027 - acc: 0.8564    \n",
      "Epoch 182/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5911 - acc: 0.8613    \n",
      "Epoch 183/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5934 - acc: 0.8634    \n",
      "Epoch 184/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5806 - acc: 0.8660    \n",
      "Epoch 185/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5886 - acc: 0.8583    \n",
      "Epoch 186/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5715 - acc: 0.8687    \n",
      "Epoch 187/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5637 - acc: 0.8676    \n",
      "Epoch 188/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5588 - acc: 0.8691    \n",
      "Epoch 189/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5572 - acc: 0.8675    \n",
      "Epoch 190/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5470 - acc: 0.8737    \n",
      "Epoch 191/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5366 - acc: 0.8779    \n",
      "Epoch 192/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5401 - acc: 0.8739    \n",
      "Epoch 193/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5308 - acc: 0.8818    \n",
      "Epoch 194/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5309 - acc: 0.8789    \n",
      "Epoch 195/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5190 - acc: 0.8807    \n",
      "Epoch 196/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5184 - acc: 0.8823    \n",
      "Epoch 197/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5107 - acc: 0.8835    \n",
      "Epoch 198/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5058 - acc: 0.8820    \n",
      "Epoch 199/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.5063 - acc: 0.8869    \n",
      "Epoch 200/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4991 - acc: 0.8877    \n",
      "Epoch 201/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4883 - acc: 0.8931    \n",
      "Epoch 202/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4886 - acc: 0.8881    \n",
      "Epoch 203/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4837 - acc: 0.8905    \n",
      "Epoch 204/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4792 - acc: 0.8913    \n",
      "Epoch 205/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4701 - acc: 0.8966    \n",
      "Epoch 206/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4731 - acc: 0.8951    \n",
      "Epoch 207/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4688 - acc: 0.8960    \n",
      "Epoch 208/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4544 - acc: 0.9007    \n",
      "Epoch 209/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4562 - acc: 0.8979    \n",
      "Epoch 210/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4511 - acc: 0.9027    \n",
      "Epoch 211/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4396 - acc: 0.9047    \n",
      "Epoch 212/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4379 - acc: 0.9064    \n",
      "Epoch 213/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4427 - acc: 0.9030    \n",
      "Epoch 214/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4318 - acc: 0.9083    \n",
      "Epoch 215/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4391 - acc: 0.9036    \n",
      "Epoch 216/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4299 - acc: 0.9059    \n",
      "Epoch 217/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4215 - acc: 0.9085    \n",
      "Epoch 218/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4166 - acc: 0.9089    \n",
      "Epoch 219/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4166 - acc: 0.9114    \n",
      "Epoch 220/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4089 - acc: 0.9141    \n",
      "Epoch 221/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4098 - acc: 0.9132    \n",
      "Epoch 222/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.4047 - acc: 0.9145    \n",
      "Epoch 223/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3999 - acc: 0.9143    \n",
      "Epoch 224/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3926 - acc: 0.9171    \n",
      "Epoch 225/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3878 - acc: 0.9197    \n",
      "Epoch 226/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3883 - acc: 0.9195    \n",
      "Epoch 227/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3830 - acc: 0.9202    \n",
      "Epoch 228/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3759 - acc: 0.9201    \n",
      "Epoch 229/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3815 - acc: 0.9175    \n",
      "Epoch 230/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3692 - acc: 0.9237    \n",
      "Epoch 231/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3697 - acc: 0.9211    \n",
      "Epoch 232/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3681 - acc: 0.9228    \n",
      "Epoch 233/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3582 - acc: 0.9267    \n",
      "Epoch 234/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3608 - acc: 0.9259    \n",
      "Epoch 235/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3519 - acc: 0.9282    \n",
      "Epoch 236/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3496 - acc: 0.9277    \n",
      "Epoch 237/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3485 - acc: 0.9301    \n",
      "Epoch 238/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3417 - acc: 0.9291    \n",
      "Epoch 239/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3441 - acc: 0.9300    \n",
      "Epoch 240/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3377 - acc: 0.9323    \n",
      "Epoch 241/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3308 - acc: 0.9367    \n",
      "Epoch 242/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3373 - acc: 0.9308    \n",
      "Epoch 243/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3283 - acc: 0.9338    \n",
      "Epoch 244/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3284 - acc: 0.9344    \n",
      "Epoch 245/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3187 - acc: 0.9376    \n",
      "Epoch 246/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3188 - acc: 0.9363    \n",
      "Epoch 247/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3227 - acc: 0.9347    \n",
      "Epoch 248/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3120 - acc: 0.9380    \n",
      "Epoch 249/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3152 - acc: 0.9370    \n",
      "Epoch 250/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3108 - acc: 0.9428    \n",
      "Epoch 251/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3071 - acc: 0.9412    \n",
      "Epoch 252/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3026 - acc: 0.9401    \n",
      "Epoch 253/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3081 - acc: 0.9416    \n",
      "Epoch 254/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.3021 - acc: 0.9394    \n",
      "Epoch 255/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2981 - acc: 0.9430    \n",
      "Epoch 256/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2970 - acc: 0.9437    \n",
      "Epoch 257/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2924 - acc: 0.9459    \n",
      "Epoch 258/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2925 - acc: 0.9435    \n",
      "Epoch 259/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2870 - acc: 0.9451    \n",
      "Epoch 260/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2888 - acc: 0.9414    \n",
      "Epoch 261/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2874 - acc: 0.9445    \n",
      "Epoch 262/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2822 - acc: 0.9453    \n",
      "Epoch 263/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2797 - acc: 0.9476    \n",
      "Epoch 264/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2785 - acc: 0.9453    \n",
      "Epoch 265/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2723 - acc: 0.9489    \n",
      "Epoch 266/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2735 - acc: 0.9478    \n",
      "Epoch 267/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2758 - acc: 0.9453    \n",
      "Epoch 268/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2673 - acc: 0.9501    \n",
      "Epoch 269/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2722 - acc: 0.9476    \n",
      "Epoch 270/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2628 - acc: 0.9538    \n",
      "Epoch 271/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2631 - acc: 0.9508    \n",
      "Epoch 272/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2581 - acc: 0.9529    \n",
      "Epoch 273/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2561 - acc: 0.9555    \n",
      "Epoch 274/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2549 - acc: 0.9522    \n",
      "Epoch 275/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2561 - acc: 0.9522    \n",
      "Epoch 276/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2495 - acc: 0.9561    \n",
      "Epoch 277/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2486 - acc: 0.9565    \n",
      "Epoch 278/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2471 - acc: 0.9548    \n",
      "Epoch 279/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2477 - acc: 0.9553    \n",
      "Epoch 280/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2408 - acc: 0.9590    \n",
      "Epoch 281/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2455 - acc: 0.9536    \n",
      "Epoch 282/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2360 - acc: 0.9589    \n",
      "Epoch 283/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2342 - acc: 0.9593    \n",
      "Epoch 284/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2408 - acc: 0.9573    \n",
      "Epoch 285/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2328 - acc: 0.9593    \n",
      "Epoch 286/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2298 - acc: 0.9594    \n",
      "Epoch 287/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2364 - acc: 0.9570    \n",
      "Epoch 288/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2309 - acc: 0.9591    \n",
      "Epoch 289/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2312 - acc: 0.9575    \n",
      "Epoch 290/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.2231 - acc: 0.9629    \n",
      "Epoch 291/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2245 - acc: 0.9592    \n",
      "Epoch 292/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2248 - acc: 0.9621    \n",
      "Epoch 293/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2169 - acc: 0.9631    \n",
      "Epoch 294/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2139 - acc: 0.9635    \n",
      "Epoch 295/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2134 - acc: 0.9624    \n",
      "Epoch 296/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2126 - acc: 0.9631    \n",
      "Epoch 297/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2173 - acc: 0.9607    \n",
      "Epoch 298/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.2128 - acc: 0.9633    \n",
      "Epoch 299/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2085 - acc: 0.9647    \n",
      "Epoch 300/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2100 - acc: 0.9645    \n",
      "Epoch 301/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2095 - acc: 0.9641    \n",
      "Epoch 302/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2072 - acc: 0.9643    \n",
      "Epoch 303/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2041 - acc: 0.9657    \n",
      "Epoch 304/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2037 - acc: 0.9652    \n",
      "Epoch 305/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2023 - acc: 0.9658    \n",
      "Epoch 306/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2009 - acc: 0.9667    \n",
      "Epoch 307/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1996 - acc: 0.9657    \n",
      "Epoch 308/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1994 - acc: 0.9669    \n",
      "Epoch 309/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.2011 - acc: 0.9652    \n",
      "Epoch 310/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1974 - acc: 0.9670    \n",
      "Epoch 311/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1956 - acc: 0.9670    \n",
      "Epoch 312/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1955 - acc: 0.9693    \n",
      "Epoch 313/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1904 - acc: 0.9685    \n",
      "Epoch 314/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1938 - acc: 0.9692    \n",
      "Epoch 315/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1882 - acc: 0.9695    \n",
      "Epoch 316/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1857 - acc: 0.9696    \n",
      "Epoch 317/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1874 - acc: 0.9696    \n",
      "Epoch 318/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1857 - acc: 0.9719    \n",
      "Epoch 319/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1807 - acc: 0.9700    \n",
      "Epoch 320/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1812 - acc: 0.9727    \n",
      "Epoch 321/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1827 - acc: 0.9713    \n",
      "Epoch 322/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1813 - acc: 0.9716    \n",
      "Epoch 323/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1773 - acc: 0.9725    \n",
      "Epoch 324/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1800 - acc: 0.9698    \n",
      "Epoch 325/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1754 - acc: 0.9735    \n",
      "Epoch 326/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1736 - acc: 0.9721    \n",
      "Epoch 327/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1752 - acc: 0.9723    \n",
      "Epoch 328/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1748 - acc: 0.9719    \n",
      "Epoch 329/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1731 - acc: 0.9744    \n",
      "Epoch 330/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1684 - acc: 0.9744    \n",
      "Epoch 331/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1682 - acc: 0.9745    \n",
      "Epoch 332/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1681 - acc: 0.9731    \n",
      "Epoch 333/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1693 - acc: 0.9747    \n",
      "Epoch 334/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1680 - acc: 0.9737    \n",
      "Epoch 335/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1714 - acc: 0.9711    \n",
      "Epoch 336/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1637 - acc: 0.9757    \n",
      "Epoch 337/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1654 - acc: 0.9745    \n",
      "Epoch 338/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1599 - acc: 0.9755    \n",
      "Epoch 339/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1632 - acc: 0.9743    \n",
      "Epoch 340/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1593 - acc: 0.9759    \n",
      "Epoch 341/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1588 - acc: 0.9766    \n",
      "Epoch 342/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1553 - acc: 0.9777    \n",
      "Epoch 343/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1537 - acc: 0.9780    \n",
      "Epoch 344/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1524 - acc: 0.9785    \n",
      "Epoch 345/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1551 - acc: 0.9771    \n",
      "Epoch 346/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1533 - acc: 0.9777    \n",
      "Epoch 347/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1567 - acc: 0.9765    \n",
      "Epoch 348/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1519 - acc: 0.9773    \n",
      "Epoch 349/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1513 - acc: 0.9781    \n",
      "Epoch 350/400\n",
      "15000/15000 [==============================] - 32s - loss: 0.1539 - acc: 0.9761    \n",
      "Epoch 351/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1503 - acc: 0.9763    \n",
      "Epoch 352/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1483 - acc: 0.9783    \n",
      "Epoch 353/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1450 - acc: 0.9793    \n",
      "Epoch 354/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1471 - acc: 0.9783    \n",
      "Epoch 355/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1492 - acc: 0.9783    \n",
      "Epoch 356/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1431 - acc: 0.9801    \n",
      "Epoch 357/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1420 - acc: 0.9790    \n",
      "Epoch 358/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1438 - acc: 0.9781    \n",
      "Epoch 359/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1391 - acc: 0.9807    \n",
      "Epoch 360/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1397 - acc: 0.9807    \n",
      "Epoch 361/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1427 - acc: 0.9797    \n",
      "Epoch 362/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1388 - acc: 0.9803    \n",
      "Epoch 363/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1354 - acc: 0.9807    \n",
      "Epoch 364/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1359 - acc: 0.9809    \n",
      "Epoch 365/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1384 - acc: 0.9793    \n",
      "Epoch 366/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1369 - acc: 0.9819    \n",
      "Epoch 367/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1337 - acc: 0.9817    \n",
      "Epoch 368/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1375 - acc: 0.9786    \n",
      "Epoch 369/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1358 - acc: 0.9792    \n",
      "Epoch 370/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1378 - acc: 0.9805    \n",
      "Epoch 371/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1343 - acc: 0.9809    \n",
      "Epoch 372/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1311 - acc: 0.9814    \n",
      "Epoch 373/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1337 - acc: 0.9802    \n",
      "Epoch 374/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1282 - acc: 0.9829    \n",
      "Epoch 375/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1322 - acc: 0.9817    \n",
      "Epoch 376/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1274 - acc: 0.9820    \n",
      "Epoch 377/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1314 - acc: 0.9805    \n",
      "Epoch 378/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1265 - acc: 0.9816    \n",
      "Epoch 379/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1260 - acc: 0.9839    \n",
      "Epoch 380/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1277 - acc: 0.9823    \n",
      "Epoch 381/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1239 - acc: 0.9840    \n",
      "Epoch 382/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1232 - acc: 0.9840    \n",
      "Epoch 383/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1239 - acc: 0.9836    \n",
      "Epoch 384/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1222 - acc: 0.9828    \n",
      "Epoch 385/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1238 - acc: 0.9838    \n",
      "Epoch 386/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1272 - acc: 0.9811    \n",
      "Epoch 387/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1214 - acc: 0.9837    \n",
      "Epoch 388/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1238 - acc: 0.9824    \n",
      "Epoch 389/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1231 - acc: 0.9826    \n",
      "Epoch 390/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1177 - acc: 0.9859    \n",
      "Epoch 391/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1200 - acc: 0.9843    \n",
      "Epoch 392/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1171 - acc: 0.9857    \n",
      "Epoch 393/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1174 - acc: 0.9842    \n",
      "Epoch 394/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1144 - acc: 0.9857    \n",
      "Epoch 395/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1179 - acc: 0.9825    \n",
      "Epoch 396/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1171 - acc: 0.9857    \n",
      "Epoch 397/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1149 - acc: 0.9844    \n",
      "Epoch 398/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1199 - acc: 0.9823    \n",
      "Epoch 399/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1155 - acc: 0.9835    \n",
      "Epoch 400/400\n",
      "15000/15000 [==============================] - 33s - loss: 0.1120 - acc: 0.9863    \n",
      "acc: 41.58%\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "           AisKacang       0.48      0.49      0.49        51\n",
      "           AngKuKueh       0.23      0.16      0.18        45\n",
      "           ApamBalik       0.46      0.52      0.49        52\n",
      "           Asamlaksa       0.29      0.29      0.29        48\n",
      "              Bahulu       0.66      0.75      0.70        55\n",
      "           Bakkukteh       0.56      0.62      0.59        48\n",
      "      BananaLeafRice       0.57      0.41      0.48        49\n",
      "             Bazhang       0.37      0.23      0.29        47\n",
      "         BeefRendang       0.63      0.74      0.68        42\n",
      "           BingkaUbi       0.61      0.71      0.66        38\n",
      "         Buburchacha       0.56      0.52      0.54        52\n",
      "          Buburpedas       0.57      0.71      0.63        42\n",
      "              Capati       0.25      0.33      0.29        39\n",
      "              Cendol       0.36      0.28      0.31        58\n",
      "         ChaiTowKuay       0.69      0.76      0.72        62\n",
      "        CharKuehTiao       0.57      0.58      0.57        45\n",
      "             CharSiu       0.50      0.57      0.53        47\n",
      "       CheeCheongFun       0.67      0.81      0.73        47\n",
      "           ChiliCrab       0.25      0.24      0.24        55\n",
      "           Chweekueh       0.49      0.50      0.49        40\n",
      "         ClayPotRice       0.24      0.20      0.22        44\n",
      "          CucurUdang       0.35      0.18      0.24        44\n",
      "          CurryLaksa       0.22      0.19      0.21        52\n",
      "           CurryPuff       0.19      0.18      0.19        39\n",
      "               Dodol       0.24      0.29      0.27        38\n",
      "              Durian       0.27      0.39      0.32        31\n",
      "         DurianCrepe       0.29      0.35      0.32        52\n",
      "       FishHeadCurry       0.26      0.26      0.26        46\n",
      "               Guava       0.26      0.23      0.24        48\n",
      "HainaneseChickenRice       0.34      0.26      0.29        58\n",
      "          HokkienMee       0.33      0.34      0.33        53\n",
      "            Huatkuih       0.50      0.60      0.55        43\n",
      "           IkanBakar       0.39      0.44      0.41        43\n",
      "            Kangkung       0.53      0.36      0.43        58\n",
      "           KayaToast       0.40      0.35      0.38        54\n",
      "            Keklapis       0.24      0.27      0.25        60\n",
      "             Ketupat       0.43      0.50      0.46        42\n",
      "           KuihDadar       0.26      0.23      0.24        48\n",
      "           KuihLapis       0.52      0.60      0.55        57\n",
      "        KuihSeriMuka       0.24      0.26      0.25        50\n",
      "             Langsat       0.45      0.42      0.43        60\n",
      "               Lekor       0.22      0.17      0.19        46\n",
      "              Lemang       0.45      0.44      0.44        48\n",
      "         LepatPisang       0.25      0.25      0.25        52\n",
      "              LorMee       0.50      0.57      0.53        54\n",
      "        Maggi goreng       0.63      0.75      0.69        48\n",
      "          Mangosteen       0.31      0.27      0.29        49\n",
      "           MeeGoreng       0.40      0.37      0.38        54\n",
      "         MeeHoonKueh       0.57      0.42      0.48        48\n",
      "         MeeHoonSoup       0.24      0.34      0.28        44\n",
      "             MeeJawa       0.43      0.64      0.51        47\n",
      "            MeeRebus       0.54      0.59      0.56        51\n",
      "            MeeRojak       0.33      0.33      0.33        57\n",
      "             MeeSiam       0.46      0.42      0.44        62\n",
      "            Murtabak       0.49      0.42      0.45        52\n",
      "             Murukku       0.45      0.48      0.46        52\n",
      "   NasiGorengKampung       0.60      0.59      0.60        59\n",
      "           NasiImpit       0.40      0.45      0.43        55\n",
      "          Nasikandar       0.56      0.53      0.54        55\n",
      "           Nasilemak       0.24      0.16      0.19        50\n",
      "         Nasipattaya       0.36      0.42      0.38        48\n",
      "          Ondehondeh       0.36      0.39      0.38        51\n",
      "            Otakotak       0.46      0.67      0.55        49\n",
      "      OysterOmelette       0.40      0.51      0.45        49\n",
      "              PanMee       0.23      0.24      0.24        49\n",
      "       PineappleTart       0.25      0.13      0.17        61\n",
      "        PisangGoreng       0.53      0.57      0.55        44\n",
      "              Popiah       0.52      0.52      0.52        65\n",
      "            PrawnMee       0.27      0.31      0.29        59\n",
      "         Prawnsambal       0.38      0.36      0.37        58\n",
      "                Puri       0.45      0.31      0.37        48\n",
      "           PutuMayam       0.34      0.31      0.33        48\n",
      "          PutuPiring       0.28      0.22      0.25        49\n",
      "            Rambutan       0.25      0.26      0.25        47\n",
      "               Rojak       0.62      0.79      0.69        56\n",
      "           RotiCanai       0.31      0.26      0.28        54\n",
      "            RotiJala       0.46      0.49      0.48        53\n",
      "            RotiJohn       0.57      0.71      0.63        55\n",
      "            RotiNaan       0.38      0.38      0.38        60\n",
      "          RotiTissue       0.17      0.18      0.17        39\n",
      "         SambalPetai       0.53      0.40      0.46        58\n",
      "         SambalUdang       0.45      0.41      0.43        46\n",
      "               Satay       0.36      0.48      0.41        50\n",
      "          Sataycelup       0.56      0.41      0.47        49\n",
      "            SeriMuka       0.71      0.83      0.77        48\n",
      "            SotoAyam       0.41      0.44      0.42        41\n",
      "     TandooriChicken       0.18      0.27      0.22        45\n",
      "            TangYuan       0.45      0.35      0.40        54\n",
      "           TauFooFah       0.71      0.75      0.73        56\n",
      "         TauhuSumbat       0.20      0.15      0.17        53\n",
      "              Thosai       0.24      0.38      0.29        42\n",
      "          TomYumSoup       0.62      0.68      0.65        41\n",
      "               Wajik       0.15      0.11      0.13        55\n",
      "           WanTanMee       0.36      0.25      0.30        48\n",
      "             WaTanHo       0.41      0.28      0.33        58\n",
      "              Wonton       0.37      0.28      0.32        57\n",
      "             YamCake       0.28      0.25      0.26        52\n",
      "           YongTauFu       0.70      0.79      0.74        47\n",
      "             Youtiao       0.33      0.26      0.29        46\n",
      "             Yusheng       0.44      0.51      0.47        47\n",
      "\n",
      "         avg / total       0.41      0.42      0.41      5000\n",
      "\n",
      "[[25  0  1 ...,  0  0  0]\n",
      " [ 0  7  1 ...,  0  0  0]\n",
      " [ 0  0 27 ...,  0  0  0]\n",
      " ..., \n",
      " [ 0  0  0 ..., 37  0  0]\n",
      " [ 0  0  0 ...,  1 12  0]\n",
      " [ 2  0  0 ...,  0  0 24]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/machine/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'st' parameter is not going to exist anymore as it is going to be replaced by the parameter 'stride'.\n",
      "  mode='max')\n",
      "/home/machine/anaconda2/lib/python2.7/site-packages/keras/backend/theano_backend.py:1500: UserWarning: DEPRECATION: the 'padding' parameter is not going to exist anymore as it is going to be replaced by the parameter 'pad'.\n",
      "  mode='max')\n"
     ]
    }
   ],
   "source": [
    "from keras.optimizers import SGD\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.layers import Flatten, Dense, Dropout, Reshape, Permute, Activation, \\\n",
    "    Input, merge\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from convnetskeras.customlayers import convolution2Dgroup, crosschannelnormalization, \\\n",
    "    splittensor, Softmax4D\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import json\n",
    "import os.path\n",
    "\n",
    "import h5py as h5\n",
    "import numpy as np\n",
    "\n",
    "import util\n",
    "import config\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "nb_train_samples = 1500\n",
    "nb_validation_samples = 500\n",
    "nb_class = 100\n",
    "top_model_weights_path = \"bottleneck_fc_model.h5\"\n",
    "\n",
    "def get_layer_weights(weights_file=None, layer_name=None):\n",
    "    if not weights_file or not layer_name:\n",
    "        return None\n",
    "    else:\n",
    "        g = weights_file[layer_name]\n",
    "        weights = [g[p] for p in g]\n",
    "        print 'Weights for \"{}\" are loaded'.format(layer_name)\n",
    "    return weights\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    # load your data using this function\n",
    "    f = open(\"../dataset/myfood100-227.pkl\", 'rb')\n",
    "    d = pickle.load(f)\n",
    "    data = d['trainFeatures']\n",
    "    labels = d['trainLabels']\n",
    "    lz = d['labels']\n",
    "    data = data.reshape(data.shape[0], 3, 227, 227)\n",
    "    #data = data.transpose(0, 2, 3, 1)\n",
    "\n",
    "    return data,labels,lz\n",
    "\n",
    "''''\n",
    "def get_top_model_for_alexnet(nb_class=None, shape=None, W_regularizer=False, weights_file_path=None, input=None, output=None):\n",
    "    if not output:\n",
    "        inputs = Input(shape=shape)\n",
    "        x = Flatten(name='flatten')(inputs)\n",
    "    else:\n",
    "        x = Flatten(name='flatten', input_shape=shape)(output)\n",
    "\n",
    "    if weights_file_path:\n",
    "        weights_file = h5.File(top_model_weights_path)\n",
    "\n",
    "    weights_1 = get_layer_weights(weights_file, 'dense_1')\n",
    "    dense_1 = Dense(4096, activation='relu',name='dense_1',weights=weights_1)(x)\n",
    "    dense_2 = Dropout(0.5)(dense_1)\n",
    "\n",
    "\n",
    "    weights_2 = get_layer_weights(weights_file, 'dense_2')\n",
    "    dense_2 = Dense(4096, activation='relu',name='dense_2',weights=weights_2)(dense_2)\n",
    "    dense_3 = Dropout(0.5)(dense_2)\n",
    "\n",
    "    weights_3 = get_layer_weights(weights_file, 'softmax')\n",
    "    dense_3 = Dense(10,name='dense_3',weights=weights_3)(dense_3)\n",
    "    predictions = Activation(\"softmax\",name=\"softmax\")(dense_3)\n",
    "    model = Model(input=input or inputs, output=predictions)\n",
    "\n",
    "\n",
    "    if weights_file:\n",
    "        weights_file.close()\n",
    "\n",
    "    return model\n",
    "'''\n",
    "\n",
    "def get_top_model_for_alexnet(nb_class=None, shape=None, W_regularizer=False, weights_file_path=None, input=None, output=None):\n",
    "\n",
    "    if not output:\n",
    "        inputs = Input(shape=shape)\n",
    "        x = Flatten(name='flatten')(inputs)\n",
    "    else:\n",
    "        x = Flatten(name='flatten', input_shape=shape)(output)\n",
    "\n",
    "\n",
    "    dense_1 = Dense(4096, activation='relu',name='dense_1')(x)\n",
    "    dense_2 = Dropout(0.5)(dense_1)\n",
    "\n",
    "\n",
    "    dense_2 = Dense(4096, activation='relu',name='dense_2')(dense_2)\n",
    "    dense_3 = Dropout(0.5)(dense_2)\n",
    "\n",
    "\n",
    "    dense_3 = Dense(100,name='dense_3')(dense_3)\n",
    "    predictions = Activation(\"softmax\",name=\"softmax\")(dense_3)\n",
    "    model = Model(input=input, output=predictions)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model(nb_class, weights_path=None):\n",
    "\n",
    "    inputs = Input(shape=(3,227,227))\n",
    "\n",
    "    conv_1 = Convolution2D(96, 11, 11,subsample=(4,4),activation='relu',\n",
    "                           name='conv_1')(inputs)\n",
    "\n",
    "    conv_2 = MaxPooling2D((3, 3), strides=(2,2))(conv_1)\n",
    "    conv_2 = crosschannelnormalization(name=\"convpool_1\")(conv_2)\n",
    "    conv_2 = ZeroPadding2D((2,2))(conv_2)\n",
    "    conv_2 = merge([\n",
    "        Convolution2D(128,5,5,activation=\"relu\",name='conv_2_'+str(i+1))(\n",
    "            splittensor(ratio_split=2,id_split=i)(conv_2)\n",
    "        ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_2\")\n",
    "\n",
    "    conv_3 = MaxPooling2D((3, 3), strides=(2, 2))(conv_2)\n",
    "    conv_3 = crosschannelnormalization()(conv_3)\n",
    "    conv_3 = ZeroPadding2D((1,1))(conv_3)\n",
    "    conv_3 = Convolution2D(384,3,3,activation='relu',name='conv_3')(conv_3)\n",
    "\n",
    "    conv_4 = ZeroPadding2D((1,1))(conv_3)\n",
    "    conv_4 = merge([\n",
    "        Convolution2D(192,3,3,activation=\"relu\",name='conv_4_'+str(i+1))(\n",
    "            splittensor(ratio_split=2,id_split=i)(conv_4)\n",
    "        ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_4\")\n",
    "\n",
    "    conv_5 = ZeroPadding2D((1,1))(conv_4)\n",
    "    conv_5 = merge([\n",
    "        Convolution2D(128,3,3,activation=\"relu\",name='conv_5_'+str(i+1))(\n",
    "            splittensor(ratio_split=2,id_split=i)(conv_5)\n",
    "        ) for i in range(2)], mode='concat',concat_axis=1,name=\"conv_5\")\n",
    "\n",
    "    conv_5 = MaxPooling2D((3, 3), strides=(2,2),name=\"convpool_5\")(conv_5)\n",
    "\n",
    "\n",
    "\n",
    "    dense_1 = Flatten(name=\"flatten\")(conv_5)\n",
    "    dense_1 = Dense(4096, activation='relu',name='dense_1')(dense_1)\n",
    "    dense_2 = Dropout(0.5)(dense_1)\n",
    "    dense_2 = Dense(4096, activation='relu',name='dense_2')(dense_2)\n",
    "    dense_3 = Dropout(0.5)(dense_2)\n",
    "    dense_3 = Dense(nb_class,name='dense_3')(dense_3)\n",
    "    prediction = Activation(\"softmax\",name=\"softmax\")(dense_3)\n",
    "\n",
    "\n",
    "    base_model = Model(input=inputs, output=prediction)\n",
    "\n",
    "    if weights_path:\n",
    "        base_model.load_weights(weights_path)\n",
    "\n",
    "\n",
    "    model = Model(input=inputs, output=conv_5)\n",
    "\n",
    "    base_model = Model(input=inputs, output=conv_5)\n",
    "\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "\n",
    "    model = get_top_model_for_alexnet(\n",
    "        shape=base_model.output_shape[1:],\n",
    "        nb_class=nb_class,\n",
    "        #weights_file_path=\"bottleneck_fc_model.h5\",\n",
    "        input=base_model.input,\n",
    "        output=base_model.output)\n",
    "\n",
    "    return model\n",
    "\n",
    "def tune(X_train, X_test, y_train, y_test):\n",
    "    y_train = np_utils.to_categorical(y_train, nb_class)\n",
    "    y_test = np_utils.to_categorical(y_test, nb_class)\n",
    "\n",
    "    model = load_model(nb_class=nb_class, weights_path=\"../dataset/alexnet_weights.h5\")\n",
    "\n",
    "    model.compile(\n",
    "        loss='categorical_crossentropy',\n",
    "        optimizer=SGD(lr=0.0001, decay=1e-6, momentum=0.9, nesterov=True),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    print \"Fine-tuning CNN..\"\n",
    "\n",
    "    model.fit(X_train, y_train,\n",
    "              nb_epoch=400, batch_size=32,verbose=1)\n",
    "\n",
    "    scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "    y_proba = model.predict(X_test)\n",
    "    y_pred = np_utils.probas_to_classes(y_proba)\n",
    "\n",
    "    target_names = ['AisKacang' , 'AngKuKueh' , 'ApamBalik' , 'Asamlaksa' , 'Bahulu' , 'Bakkukteh',\n",
    "         'BananaLeafRice' , 'Bazhang' , 'BeefRendang' , 'BingkaUbi' , 'Buburchacha',\n",
    "         'Buburpedas' , 'Capati' , 'Cendol' , 'ChaiTowKuay' , 'CharKuehTiao' , 'CharSiu',\n",
    "         'CheeCheongFun' , 'ChiliCrab' , 'Chweekueh' , 'ClayPotRice' , 'CucurUdang',\n",
    "         'CurryLaksa' , 'CurryPuff' , 'Dodol' , 'Durian' , 'DurianCrepe' , 'FishHeadCurry',\n",
    "         'Guava' , 'HainaneseChickenRice' , 'HokkienMee' , 'Huatkuih' , 'IkanBakar',\n",
    "         'Kangkung' , 'KayaToast' , 'Keklapis' , 'Ketupat' , 'KuihDadar' , 'KuihLapis',\n",
    "         'KuihSeriMuka' , 'Langsat' , 'Lekor' , 'Lemang' , 'LepatPisang' , 'LorMee',\n",
    "         'Maggi goreng' , 'Mangosteen' , 'MeeGoreng' , 'MeeHoonKueh' , 'MeeHoonSoup',\n",
    "         'MeeJawa' , 'MeeRebus' , 'MeeRojak' , 'MeeSiam' , 'Murtabak' , 'Murukku',\n",
    "         'NasiGorengKampung' , 'NasiImpit' , 'Nasikandar' , 'Nasilemak' , 'Nasipattaya',\n",
    "         'Ondehondeh' , 'Otakotak' , 'OysterOmelette' , 'PanMee' , 'PineappleTart',\n",
    "         'PisangGoreng' , 'Popiah' , 'PrawnMee' , 'Prawnsambal' , 'Puri' , 'PutuMayam',\n",
    "         'PutuPiring' , 'Rambutan' , 'Rojak' , 'RotiCanai' , 'RotiJala' , 'RotiJohn',\n",
    "         'RotiNaan' , 'RotiTissue' , 'SambalPetai' , 'SambalUdang' , 'Satay' , 'Sataycelup',\n",
    "         'SeriMuka' , 'SotoAyam' , 'TandooriChicken' , 'TangYuan' , 'TauFooFah',\n",
    "         'TauhuSumbat' , 'Thosai' , 'TomYumSoup' , 'Wajik' , 'WanTanMee' , 'WaTanHo' , 'Wonton',\n",
    "         'YamCake' , 'YongTauFu' , 'Youtiao' , 'Yusheng']\n",
    "\n",
    "    print(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\n",
    "    print(confusion_matrix(np.argmax(y_test,axis=1), y_pred))\n",
    "\n",
    "    model.save_weights(\"alex_finetune_weights.h5\")\n",
    "\n",
    "\n",
    "print \"Loading data..\"\n",
    "data, labels, lz = load_data()\n",
    "data = data.astype('float32')\n",
    "data /= 255\n",
    "lz = np.array(lz)\n",
    "print \"Data loaded !\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.25)\n",
    "tune(X_train, X_test, y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
