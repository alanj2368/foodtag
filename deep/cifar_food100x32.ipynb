{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "('Running Fold', 1, '/', 2)\n",
      "Training..\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 11s - loss: 4.6084 - acc: 0.0089 - val_loss: 4.6052 - val_acc: 0.0116\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 11s - loss: 4.6070 - acc: 0.0093 - val_loss: 4.6038 - val_acc: 0.0135\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 11s - loss: 4.5663 - acc: 0.0152 - val_loss: 4.4434 - val_acc: 0.0260\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 12s - loss: 4.4146 - acc: 0.0243 - val_loss: 4.3398 - val_acc: 0.0280\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 11s - loss: 4.3205 - acc: 0.0335 - val_loss: 4.1832 - val_acc: 0.0502\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 11s - loss: 4.1953 - acc: 0.0497 - val_loss: 4.1063 - val_acc: 0.0618\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 12s - loss: 4.0871 - acc: 0.0604 - val_loss: 4.0195 - val_acc: 0.0765\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 12s - loss: 3.9917 - acc: 0.0705 - val_loss: 3.8894 - val_acc: 0.0861\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 12s - loss: 3.8956 - acc: 0.0842 - val_loss: 3.7844 - val_acc: 0.1047\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.8182 - acc: 0.0984 - val_loss: 3.6787 - val_acc: 0.1235\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.7493 - acc: 0.1065 - val_loss: 3.6740 - val_acc: 0.1217\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.6860 - acc: 0.1178 - val_loss: 3.5780 - val_acc: 0.1404\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.6301 - acc: 0.1270 - val_loss: 3.5345 - val_acc: 0.1470\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 12s - loss: 3.5635 - acc: 0.1384 - val_loss: 3.4725 - val_acc: 0.1528\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.5219 - acc: 0.1442 - val_loss: 3.4244 - val_acc: 0.1687\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.4664 - acc: 0.1523 - val_loss: 3.3830 - val_acc: 0.1691\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.4155 - acc: 0.1621 - val_loss: 3.3802 - val_acc: 0.1752\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.3642 - acc: 0.1752 - val_loss: 3.2826 - val_acc: 0.1855\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.3147 - acc: 0.1787 - val_loss: 3.3186 - val_acc: 0.1808\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.2741 - acc: 0.1846 - val_loss: 3.2358 - val_acc: 0.1993\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.2262 - acc: 0.1903 - val_loss: 3.2017 - val_acc: 0.2067\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.2038 - acc: 0.1976 - val_loss: 3.1198 - val_acc: 0.2203\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.1536 - acc: 0.2063 - val_loss: 3.1332 - val_acc: 0.2201\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.0992 - acc: 0.2188 - val_loss: 3.1546 - val_acc: 0.2078\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.0767 - acc: 0.2146 - val_loss: 3.1097 - val_acc: 0.2299\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.0431 - acc: 0.2335 - val_loss: 3.0099 - val_acc: 0.2421\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.0227 - acc: 0.2304 - val_loss: 3.1599 - val_acc: 0.2171\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.9658 - acc: 0.2407 - val_loss: 3.0873 - val_acc: 0.2247\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.9454 - acc: 0.2488 - val_loss: 2.9999 - val_acc: 0.2487\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.9126 - acc: 0.2514 - val_loss: 2.9762 - val_acc: 0.2557\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.8884 - acc: 0.2551 - val_loss: 2.9461 - val_acc: 0.2525\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.8606 - acc: 0.2664 - val_loss: 2.9041 - val_acc: 0.2623\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.8367 - acc: 0.2668 - val_loss: 2.9698 - val_acc: 0.2559\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.8305 - acc: 0.2689 - val_loss: 2.9481 - val_acc: 0.2589\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.7736 - acc: 0.2795 - val_loss: 2.9064 - val_acc: 0.2639\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.7529 - acc: 0.2844 - val_loss: 2.9698 - val_acc: 0.2553\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.7487 - acc: 0.2815 - val_loss: 3.0191 - val_acc: 0.2414\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.7123 - acc: 0.2976 - val_loss: 2.8860 - val_acc: 0.2760\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.7279 - acc: 0.2852 - val_loss: 2.9251 - val_acc: 0.2632\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.6838 - acc: 0.2977 - val_loss: 2.8487 - val_acc: 0.2818\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.6485 - acc: 0.3059 - val_loss: 2.8249 - val_acc: 0.2823\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.6511 - acc: 0.3009 - val_loss: 2.9259 - val_acc: 0.2724\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.6206 - acc: 0.3076 - val_loss: 2.9027 - val_acc: 0.2759\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.6296 - acc: 0.3085 - val_loss: 2.8280 - val_acc: 0.2863\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.6363 - acc: 0.3167 - val_loss: 2.9215 - val_acc: 0.2635\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.6196 - acc: 0.3128 - val_loss: 2.9115 - val_acc: 0.2691\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.6009 - acc: 0.3138 - val_loss: 2.8730 - val_acc: 0.2761\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.5682 - acc: 0.3173 - val_loss: 2.8967 - val_acc: 0.2716\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.5446 - acc: 0.3217 - val_loss: 2.8459 - val_acc: 0.2858\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.5479 - acc: 0.3300 - val_loss: 2.9897 - val_acc: 0.2612\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.5287 - acc: 0.3296 - val_loss: 2.7945 - val_acc: 0.2956\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.5205 - acc: 0.3321 - val_loss: 2.8840 - val_acc: 0.2796\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.4938 - acc: 0.3385 - val_loss: 2.8284 - val_acc: 0.2903\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.5086 - acc: 0.3403 - val_loss: 2.7564 - val_acc: 0.3051\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4875 - acc: 0.3417 - val_loss: 2.7569 - val_acc: 0.3054\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4519 - acc: 0.3498 - val_loss: 2.7886 - val_acc: 0.2983\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4891 - acc: 0.3374 - val_loss: 2.7677 - val_acc: 0.3081\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4768 - acc: 0.3421 - val_loss: 2.7912 - val_acc: 0.3045\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4742 - acc: 0.3413 - val_loss: 2.7485 - val_acc: 0.3025\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4378 - acc: 0.3535 - val_loss: 2.8486 - val_acc: 0.2878\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4384 - acc: 0.3490 - val_loss: 2.7848 - val_acc: 0.2950\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4231 - acc: 0.3549 - val_loss: 2.8169 - val_acc: 0.2974\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4130 - acc: 0.3484 - val_loss: 2.8323 - val_acc: 0.2987\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4272 - acc: 0.3519 - val_loss: 2.7526 - val_acc: 0.3081\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4142 - acc: 0.3509 - val_loss: 2.8272 - val_acc: 0.2982\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4075 - acc: 0.3530 - val_loss: 2.7660 - val_acc: 0.3115\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3839 - acc: 0.3617 - val_loss: 2.7968 - val_acc: 0.2983\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3935 - acc: 0.3539 - val_loss: 2.8100 - val_acc: 0.2959\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.3673 - acc: 0.3706 - val_loss: 2.7471 - val_acc: 0.3153\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3643 - acc: 0.3686 - val_loss: 2.8936 - val_acc: 0.2917\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4053 - acc: 0.3582 - val_loss: 2.7767 - val_acc: 0.3081\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3827 - acc: 0.3623 - val_loss: 2.7232 - val_acc: 0.3145\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3431 - acc: 0.3725 - val_loss: 2.7558 - val_acc: 0.3127\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3709 - acc: 0.3622 - val_loss: 2.8439 - val_acc: 0.2979\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3388 - acc: 0.3718 - val_loss: 2.7641 - val_acc: 0.3087\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3221 - acc: 0.3783 - val_loss: 2.7829 - val_acc: 0.3016\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3916 - acc: 0.3586 - val_loss: 2.8056 - val_acc: 0.3045\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3496 - acc: 0.3733 - val_loss: 2.8900 - val_acc: 0.2884\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3509 - acc: 0.3720 - val_loss: 2.8243 - val_acc: 0.2988\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3524 - acc: 0.3681 - val_loss: 2.7455 - val_acc: 0.3114\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3535 - acc: 0.3696 - val_loss: 2.8279 - val_acc: 0.2902\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3022 - acc: 0.3779 - val_loss: 2.8102 - val_acc: 0.3060\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3291 - acc: 0.3786 - val_loss: 2.9314 - val_acc: 0.2818\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.3238 - acc: 0.3801 - val_loss: 2.7562 - val_acc: 0.3078\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3389 - acc: 0.3771 - val_loss: 2.7968 - val_acc: 0.2987\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3308 - acc: 0.3765 - val_loss: 2.8690 - val_acc: 0.2873\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3074 - acc: 0.3863 - val_loss: 2.7566 - val_acc: 0.3177\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2829 - acc: 0.3869 - val_loss: 2.8039 - val_acc: 0.3028\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2877 - acc: 0.3768 - val_loss: 2.7233 - val_acc: 0.3167\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.3021 - acc: 0.3883 - val_loss: 2.8619 - val_acc: 0.2957\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3000 - acc: 0.3925 - val_loss: 2.7793 - val_acc: 0.3053\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3022 - acc: 0.3840 - val_loss: 2.7687 - val_acc: 0.3050\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2494 - acc: 0.3856 - val_loss: 2.8244 - val_acc: 0.3041\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2726 - acc: 0.3864 - val_loss: 2.7266 - val_acc: 0.3195\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2862 - acc: 0.3784 - val_loss: 2.7731 - val_acc: 0.3074\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2997 - acc: 0.3849 - val_loss: 2.7974 - val_acc: 0.2974\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3134 - acc: 0.3790 - val_loss: 2.8155 - val_acc: 0.3083\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2994 - acc: 0.3841 - val_loss: 2.7647 - val_acc: 0.3166\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2829 - acc: 0.3848 - val_loss: 2.7782 - val_acc: 0.3077\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2493 - acc: 0.3955 - val_loss: 2.7627 - val_acc: 0.3112\n",
      "acc: 31.12%\n",
      "('Running Fold', 2, '/', 2)\n",
      "Training..\n",
      "Using real-time data augmentation.\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 11s - loss: 4.6079 - acc: 0.0082 - val_loss: 4.5984 - val_acc: 0.0168\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 11s - loss: 4.5647 - acc: 0.0141 - val_loss: 4.5432 - val_acc: 0.0228\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 11s - loss: 4.4575 - acc: 0.0246 - val_loss: 4.4198 - val_acc: 0.0233\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 11s - loss: 4.3792 - acc: 0.0322 - val_loss: 4.3427 - val_acc: 0.0403\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 11s - loss: 4.2901 - acc: 0.0392 - val_loss: 4.2092 - val_acc: 0.0440\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 11s - loss: 4.1551 - acc: 0.0561 - val_loss: 4.1064 - val_acc: 0.0586\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 12s - loss: 4.0615 - acc: 0.0676 - val_loss: 3.9434 - val_acc: 0.0859\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 10s - loss: 3.9212 - acc: 0.0854 - val_loss: 3.8331 - val_acc: 0.0925\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.8313 - acc: 0.0999 - val_loss: 3.7950 - val_acc: 0.1017\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.7617 - acc: 0.1094 - val_loss: 3.7678 - val_acc: 0.1152\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.7035 - acc: 0.1174 - val_loss: 3.6316 - val_acc: 0.1273\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.6521 - acc: 0.1264 - val_loss: 3.5121 - val_acc: 0.1526\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 10s - loss: 3.5784 - acc: 0.1305 - val_loss: 3.4764 - val_acc: 0.1589\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.5346 - acc: 0.1439 - val_loss: 3.4808 - val_acc: 0.1531\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 10s - loss: 3.4854 - acc: 0.1504 - val_loss: 3.4356 - val_acc: 0.1643\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 10s - loss: 3.4274 - acc: 0.1588 - val_loss: 3.3643 - val_acc: 0.1773\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 10s - loss: 3.3747 - acc: 0.1648 - val_loss: 3.3271 - val_acc: 0.1804\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 10s - loss: 3.3326 - acc: 0.1764 - val_loss: 3.3211 - val_acc: 0.1803\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 10s - loss: 3.2925 - acc: 0.1866 - val_loss: 3.1935 - val_acc: 0.2072\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 10s - loss: 3.2337 - acc: 0.1951 - val_loss: 3.1865 - val_acc: 0.2066\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 10s - loss: 3.2081 - acc: 0.1979 - val_loss: 3.1245 - val_acc: 0.2198\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.1657 - acc: 0.2064 - val_loss: 3.1386 - val_acc: 0.2091\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.1294 - acc: 0.2125 - val_loss: 3.1117 - val_acc: 0.2283\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.0880 - acc: 0.2233 - val_loss: 3.0817 - val_acc: 0.2204\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 11s - loss: 3.0559 - acc: 0.2257 - val_loss: 3.1236 - val_acc: 0.2239\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 10s - loss: 3.0143 - acc: 0.2328 - val_loss: 3.0384 - val_acc: 0.2367\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.9916 - acc: 0.2334 - val_loss: 2.9814 - val_acc: 0.2461\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.9591 - acc: 0.2438 - val_loss: 2.9880 - val_acc: 0.2486\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.9201 - acc: 0.2520 - val_loss: 3.0559 - val_acc: 0.2314\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.9055 - acc: 0.2557 - val_loss: 2.9827 - val_acc: 0.2457\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.8663 - acc: 0.2609 - val_loss: 2.9747 - val_acc: 0.2511\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.8466 - acc: 0.2667 - val_loss: 2.9047 - val_acc: 0.2660\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.8399 - acc: 0.2733 - val_loss: 2.8802 - val_acc: 0.2675\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.7939 - acc: 0.2825 - val_loss: 2.8704 - val_acc: 0.2749\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.7661 - acc: 0.2851 - val_loss: 2.8432 - val_acc: 0.2798\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.7627 - acc: 0.2796 - val_loss: 2.8540 - val_acc: 0.2737\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.7504 - acc: 0.2873 - val_loss: 2.8653 - val_acc: 0.2718\n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.7228 - acc: 0.2944 - val_loss: 2.8434 - val_acc: 0.2726\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.6946 - acc: 0.2992 - val_loss: 2.8213 - val_acc: 0.2831\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.6877 - acc: 0.2993 - val_loss: 2.8337 - val_acc: 0.2826\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.6829 - acc: 0.3005 - val_loss: 2.7757 - val_acc: 0.2891\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.6500 - acc: 0.3091 - val_loss: 2.9429 - val_acc: 0.2623\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.6371 - acc: 0.3140 - val_loss: 3.0023 - val_acc: 0.2491\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.6363 - acc: 0.3114 - val_loss: 2.8247 - val_acc: 0.2841\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.5883 - acc: 0.3182 - val_loss: 2.8081 - val_acc: 0.2864\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.5892 - acc: 0.3212 - val_loss: 2.9526 - val_acc: 0.2660\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.5949 - acc: 0.3162 - val_loss: 2.8173 - val_acc: 0.2861\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.5696 - acc: 0.3196 - val_loss: 2.7637 - val_acc: 0.2980\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.5488 - acc: 0.3285 - val_loss: 2.8284 - val_acc: 0.2850\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.5357 - acc: 0.3336 - val_loss: 2.7254 - val_acc: 0.3029\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.5339 - acc: 0.3368 - val_loss: 2.7997 - val_acc: 0.2899\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.5174 - acc: 0.3372 - val_loss: 2.7445 - val_acc: 0.3023\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.5016 - acc: 0.3295 - val_loss: 2.8042 - val_acc: 0.2914\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4703 - acc: 0.3478 - val_loss: 2.7955 - val_acc: 0.2924\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4864 - acc: 0.3379 - val_loss: 2.7995 - val_acc: 0.2969\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4634 - acc: 0.3456 - val_loss: 2.8268 - val_acc: 0.2841\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4643 - acc: 0.3470 - val_loss: 2.7669 - val_acc: 0.2995\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4933 - acc: 0.3413 - val_loss: 2.7864 - val_acc: 0.2960\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.4360 - acc: 0.3521 - val_loss: 2.6864 - val_acc: 0.3130\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.4654 - acc: 0.3462 - val_loss: 2.7545 - val_acc: 0.3038\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.4518 - acc: 0.3488 - val_loss: 2.7360 - val_acc: 0.3033\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4282 - acc: 0.3586 - val_loss: 2.7726 - val_acc: 0.3006\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.4165 - acc: 0.3578 - val_loss: 2.9004 - val_acc: 0.2795\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.4356 - acc: 0.3527 - val_loss: 2.7419 - val_acc: 0.3050\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.4073 - acc: 0.3685 - val_loss: 2.7269 - val_acc: 0.3138\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.4176 - acc: 0.3605 - val_loss: 2.8243 - val_acc: 0.2988\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.3795 - acc: 0.3663 - val_loss: 2.7316 - val_acc: 0.3087\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.3764 - acc: 0.3611 - val_loss: 2.7579 - val_acc: 0.3056\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3628 - acc: 0.3694 - val_loss: 2.6689 - val_acc: 0.3191\n",
      "Epoch 70/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3504 - acc: 0.3666 - val_loss: 2.7961 - val_acc: 0.2985\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3529 - acc: 0.3721 - val_loss: 2.7601 - val_acc: 0.3030\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3593 - acc: 0.3665 - val_loss: 2.8139 - val_acc: 0.3029\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3483 - acc: 0.3701 - val_loss: 2.7694 - val_acc: 0.3109\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.3562 - acc: 0.3719 - val_loss: 2.8216 - val_acc: 0.2931\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3535 - acc: 0.3673 - val_loss: 2.8284 - val_acc: 0.2944\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3309 - acc: 0.3724 - val_loss: 2.7172 - val_acc: 0.3195\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3253 - acc: 0.3793 - val_loss: 2.7091 - val_acc: 0.3196\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.3361 - acc: 0.3764 - val_loss: 2.8191 - val_acc: 0.3047\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3055 - acc: 0.3789 - val_loss: 2.7307 - val_acc: 0.3134\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2938 - acc: 0.3812 - val_loss: 2.7051 - val_acc: 0.3229\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2830 - acc: 0.3829 - val_loss: 2.7655 - val_acc: 0.3084\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3141 - acc: 0.3740 - val_loss: 2.8268 - val_acc: 0.2961\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2919 - acc: 0.3805 - val_loss: 2.8028 - val_acc: 0.3030\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2997 - acc: 0.3888 - val_loss: 2.8126 - val_acc: 0.3006\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3044 - acc: 0.3805 - val_loss: 2.7605 - val_acc: 0.3106\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2929 - acc: 0.3916 - val_loss: 2.7513 - val_acc: 0.3177\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2762 - acc: 0.3901 - val_loss: 2.8172 - val_acc: 0.2963\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3014 - acc: 0.3819 - val_loss: 2.7861 - val_acc: 0.3042\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2821 - acc: 0.3892 - val_loss: 2.7299 - val_acc: 0.3124\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2604 - acc: 0.3844 - val_loss: 2.7613 - val_acc: 0.3052\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2709 - acc: 0.3921 - val_loss: 2.7339 - val_acc: 0.3116\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2539 - acc: 0.3894 - val_loss: 2.8520 - val_acc: 0.2910\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.3030 - acc: 0.3840 - val_loss: 2.8355 - val_acc: 0.2997\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2620 - acc: 0.3903 - val_loss: 2.7409 - val_acc: 0.3113\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 12s - loss: 2.2361 - acc: 0.3998 - val_loss: 2.7524 - val_acc: 0.3109\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2087 - acc: 0.3963 - val_loss: 2.7430 - val_acc: 0.3206\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2351 - acc: 0.4001 - val_loss: 2.7895 - val_acc: 0.3151\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2354 - acc: 0.3986 - val_loss: 2.8328 - val_acc: 0.3048\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 10s - loss: 2.2249 - acc: 0.4020 - val_loss: 2.8964 - val_acc: 0.2795\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 11s - loss: 2.2347 - acc: 0.3975 - val_loss: 2.7343 - val_acc: 0.3111\n",
      "acc: 31.11%\n",
      "Average acc : 31.11% (+/- 0.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import StratifiedKFold\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "batch_size = 32\n",
    "nb_classes = 100\n",
    "nb_epoch = 10\n",
    "data_augmentation = True\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 32, 32\n",
    "# the CIFAR10 images are RGB\n",
    "img_channels = 3\n",
    "\n",
    "def load_data():\n",
    "    # load your data using this function\n",
    "    f = open(\"../dataset/myfood100-32.pkl\", 'rb')\n",
    "\n",
    "    d = pickle.load(f)\n",
    "    data = d['trainFeatures']\n",
    "    labels = d['trainLabels']\n",
    "    lz = d['labels']\n",
    "    data = data.reshape(data.shape[0], 3, 32, 32)\n",
    "    #data = data.transpose(0, 2, 3, 1)\n",
    "\n",
    "    return data,labels,lz\n",
    "\n",
    "def create_model():\n",
    "    # create your model using this function\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Convolution2D(32, 3, 3, border_mode='same', input_shape=(3,32,32)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(32, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, border_mode='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Convolution2D(64, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=sgd,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "def train_and_evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    print \"Training..\"\n",
    "    \n",
    "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "    if not data_augmentation:\n",
    "        print('Not using data augmentation.')\n",
    "        #model.fit(X_train, Y_train,\n",
    "        #          batch_size=batch_size,\n",
    "        #          nb_epoch=nb_epoch,\n",
    "        #          validation_data=(X_test, Y_test),\n",
    "        #          shuffle=True)\n",
    "        \n",
    "        model.fit(X_train, Y_train, nb_epoch=nb_epoch, batch_size=batch_size, verbose=0)\n",
    "\n",
    "        scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        \n",
    "    \n",
    "    else:\n",
    "        print('Using real-time data augmentation.')\n",
    "\n",
    "        # this will do preprocessing and realtime data augmentation\n",
    "        datagen = ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=False)  # randomly flip images\n",
    "\n",
    "        # compute quantities required for featurewise normalization\n",
    "        # (std, mean, and principal components if ZCA whitening is applied)\n",
    "        datagen.fit(X_train)\n",
    "\n",
    "        # fit the model on the batches generated by datagen.flow()\n",
    "        model.fit_generator(datagen.flow(X_train, Y_train,\n",
    "                            batch_size=batch_size),\n",
    "                            samples_per_epoch=X_train.shape[0],\n",
    "                            nb_epoch=nb_epoch,\n",
    "                            validation_data=(X_test, Y_test))\n",
    "        \n",
    "        scores = model.evaluate(X_test, Y_test, verbose=0)\n",
    "        print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "        \n",
    "    return scores\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    n_folds = 2\n",
    "    cvscores = []\n",
    "    print \"Loading data\"\n",
    "    data, labels, lz = load_data()\n",
    "    data = data.astype('float32')\n",
    "    data /= 255\n",
    "    lz = np.array(lz)\n",
    "    \n",
    "\n",
    "    skf = StratifiedKFold(y=lz, n_folds=n_folds, shuffle=True)\n",
    "\n",
    "    for i, (train, test) in enumerate(skf):\n",
    "        print (\"Running Fold\", i+1, \"/\", n_folds)\n",
    "        model = None # Clearing the NN.\n",
    "        model = create_model()\n",
    "        scores = train_and_evaluate_model(model, data[train], labels[train], data[test], labels[test])\n",
    "        cvscores.append(scores[1] * 100)\n",
    "        \n",
    "    print(\"Average acc : %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Running Fold', 1, '/', 2)\n",
      "Training..\n",
      "Not using data augmentation.\n",
      "acc: 16.59%\n",
      "('Running Fold', 2, '/', 2)\n",
      "Training..\n",
      "Not using data augmentation.\n",
      "acc: 16.54%\n",
      "Average acc : 16.56% (+/- 0.03%)\n"
     ]
    }
   ],
   "source": [
    "data_augmentation = False\n",
    "cvscores = []\n",
    "for i, (train, test) in enumerate(skf):\n",
    "        print (\"Running Fold\", i+1, \"/\", n_folds)\n",
    "        model = None # Clearing the NN.\n",
    "        model = create_model()\n",
    "        scores = train_and_evaluate_model(model, data[train], labels[train], data[test], labels[test])\n",
    "        cvscores.append(scores[1] * 100)\n",
    "        \n",
    "print(\"Average acc : %.2f%% (+/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4aab354ca940>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
