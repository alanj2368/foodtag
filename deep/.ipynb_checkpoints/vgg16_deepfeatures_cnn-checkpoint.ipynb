{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data..\n",
      "Data loaded !\n",
      "(1700, 3, 224, 224)\n",
      "(300, 3, 224, 224)\n",
      "Test train splitted !\n",
      "(1700, 512, 7, 7)\n",
      "(300, 512, 7, 7)\n",
      "Training CNN..\n",
      "Epoch 1/10\n",
      "1700/1700 [==============================] - 8s - loss: 112.5637 - acc: 0.2471     \n",
      "Epoch 2/10\n",
      "1700/1700 [==============================] - 8s - loss: 109.5349 - acc: 0.4341     \n",
      "Epoch 3/10\n",
      "1700/1700 [==============================] - 8s - loss: 106.8761 - acc: 0.5335     \n",
      "Epoch 4/10\n",
      "1700/1700 [==============================] - 8s - loss: 104.5086 - acc: 0.5882     \n",
      "Epoch 5/10\n",
      "1700/1700 [==============================] - 8s - loss: 102.2102 - acc: 0.6341     \n",
      "Epoch 6/10\n",
      "1700/1700 [==============================] - 8s - loss: 99.8923 - acc: 0.6706     \n",
      "Epoch 7/10\n",
      "1700/1700 [==============================] - 8s - loss: 97.6824 - acc: 0.7188     \n",
      "Epoch 8/10\n",
      "1700/1700 [==============================] - 8s - loss: 95.5440 - acc: 0.7471     \n",
      "Epoch 9/10\n",
      "1700/1700 [==============================] - 8s - loss: 93.4471 - acc: 0.7624     \n",
      "Epoch 10/10\n",
      "1700/1700 [==============================] - 8s - loss: 91.5003 - acc: 0.7700     \n",
      "acc: 68.33%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.utils import column_or_1d\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "from sklearn import svm\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "import util\n",
    "\n",
    "try:\n",
    "    import cPickle as pickle\n",
    "except:\n",
    "    import pickle\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# path to the model weights file.\n",
    "weights_path = '../dataset/vgg16_weights.h5'\n",
    "top_model_weights_path = 'bottleneck_fc_model.h5'\n",
    "f_model = './model'\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "nb_classes = 10\n",
    "\n",
    "nb_train_samples = 1700\n",
    "nb_validation_samples = 300\n",
    "nb_epoch = 10\n",
    "\n",
    "\n",
    "def get_layer_weights(weights_file=None, layer_name=None):\n",
    "    if not weights_file or not layer_name:\n",
    "        return None\n",
    "    else:\n",
    "        g = weights_file[layer_name]\n",
    "        weights = [g[p] for p in g]\n",
    "        print 'Weights for \"{}\" are loaded'.format(layer_name)\n",
    "        return weights\n",
    "\n",
    "def load_data():\n",
    "    # load your data using this function\n",
    "    f = open(\"../dataset/myfood10-224.pkl\", 'rb')\n",
    "    d = pickle.load(f)\n",
    "    data = d['trainFeatures']\n",
    "    labels = d['trainLabels']\n",
    "    lz = d['labels']\n",
    "    data = data.reshape(data.shape[0], 3, 224, 224)\n",
    "    #data = data.transpose(0, 2, 3, 1)\n",
    "\n",
    "    return data,labels,lz\n",
    "\n",
    "def save_bottlebeck_features(X_train, X_test, y_train, y_test):\n",
    "    weights_path='../dataset/vgg16_weights.h5'\n",
    "    # build the VGG16 network\n",
    "    model = Sequential()\n",
    "    model.add(ZeroPadding2D((1, 1), input_shape=(3, img_width, img_height)))\n",
    "\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', name='conv1_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu', name='conv2_2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu', name='conv3_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv4_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_1'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_2'))\n",
    "    model.add(ZeroPadding2D((1, 1)))\n",
    "    model.add(Convolution2D(512, 3, 3, activation='relu', name='conv5_3'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2)))\n",
    "\n",
    "\n",
    "    assert os.path.exists(weights_path), 'Model weights not found (see \"weights_path\" variable in script).'\n",
    "    f = h5py.File(weights_path)\n",
    "    for k in range(f.attrs['nb_layers']):\n",
    "        if k >= len(model.layers):\n",
    "            # we don't look at the last (fully-connected) layers in the savefile\n",
    "            break\n",
    "        g = f['layer_{}'.format(k)]\n",
    "        weights = [g['param_{}'.format(p)] for p in range(g.attrs['nb_params'])]\n",
    "        model.layers[k].set_weights(weights)\n",
    "    f.close()\n",
    "    print('Model loaded.')\n",
    "\n",
    "    bottleneck_features_train = model.predict(X_train, batch_size=32)\n",
    "    np.save(open('bottleneck_features_train.npy', 'wb'), bottleneck_features_train)\n",
    "\n",
    "\n",
    "    bottleneck_features_validation = model.predict(X_test, batch_size=32)\n",
    "    np.save(open('bottleneck_features_validation.npy', 'wb'), bottleneck_features_validation)\n",
    "\n",
    "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.jet):\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(10)\n",
    "    plt.xticks(tick_marks, ['AisKacang' , 'AngKuKueh' , 'ApamBalik' , 'Asamlaksa' , 'Bahulu' , 'Bakkukteh',\n",
    "    'BananaLeafRice' , 'Bazhang' , 'BeefRendang' , 'BingkaUbi'], rotation=45)\n",
    "    plt.yticks(tick_marks, ['AisKacang' , 'AngKuKueh' , 'ApamBalik' , 'Asamlaksa' , 'Bahulu' , 'Bakkukteh',\n",
    "    'BananaLeafRice' , 'Bazhang' , 'BeefRendang' , 'BingkaUbi'])\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "'''\n",
    "def train_top_model(y_train, y_test):\n",
    "    train_data = np.load(open('bottleneck_features_train.npy' , 'rb'))\n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy', 'rb'))\n",
    "\n",
    "\n",
    "    print train_data.shape\n",
    "    print validation_data.shape\n",
    "    print \"Training CNN..\"\n",
    "\n",
    "    input = None\n",
    "    shape=train_data.shape[1:]\n",
    "    output = None\n",
    "    W_regularizer=True\n",
    "    weights_file_path = None\n",
    "    weights_file = None\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(name='flatten', input_shape=shape))\n",
    "    W_regularizer = l2(1e-2)\n",
    "    model.add(Dense(4096, activation='relu',W_regularizer=W_regularizer))\n",
    "    model.add(Dropout(0.6))\n",
    "    W_regularizer = l2(1e-2)\n",
    "    model.add(Dense(4096, activation='relu',W_regularizer=W_regularizer))\n",
    "    model.add(Dense(nb_classes,activation='softmax'))\n",
    "\n",
    "    rms = RMSprop(lr=5e-4, rho=0.9, epsilon=1e-08, decay=0.01)\n",
    "    model.compile(optimizer=rms, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, y_train,\n",
    "              nb_epoch=nb_epoch, batch_size=32,\n",
    "              validation_data=(validation_data, y_test))\n",
    "\n",
    "    Y_pred = model.predict(validation_data)\n",
    "    print(Y_pred)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    print(y_pred)\n",
    "'''\n",
    "if __name__ == \"__main__\":\n",
    "    print \"Loading data..\"\n",
    "    data, labels, lz = load_data()\n",
    "    data = data.astype('float32')\n",
    "    data /= 255\n",
    "    lz = np.array(lz)\n",
    "    print \"Data loaded !\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.15, random_state=seed)\n",
    "    print X_train.shape\n",
    "    print X_test.shape\n",
    "    print \"Test train splitted !\"\n",
    "\n",
    "    #save_bottlebeck_features(X_train, X_test, y_train, y_test)\n",
    "    #train_top_model(y_train, y_test)\n",
    "    train_data = np.load(open('bottleneck_features_train.npy' , 'rb'))\n",
    "    validation_data = np.load(open('bottleneck_features_validation.npy', 'rb'))\n",
    "\n",
    "\n",
    "    print train_data.shape\n",
    "    print validation_data.shape\n",
    "    print \"Training CNN..\"\n",
    "\n",
    "    input = None\n",
    "    shape=train_data.shape[1:]\n",
    "    output = None\n",
    "    W_regularizer=None\n",
    "    weights_file_path = None\n",
    "    weights_file = None\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(name='flatten', input_shape=shape))\n",
    "    #W_regularizer = l2(1e-2)\n",
    "    model.add(Dense(4096, activation='relu',W_regularizer=W_regularizer))\n",
    "    model.add(Dropout(0.6))\n",
    "    #W_regularizer = l2(1e-2)\n",
    "    model.add(Dense(4096, activation='relu',W_regularizer=W_regularizer))\n",
    "    model.add(Dense(nb_classes,activation='softmax'))\n",
    "\n",
    "    opt = SGD(lr=0.01)\n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, y_train, nb_epoch=nb_epoch, batch_size=32)\n",
    "    \n",
    "    model.save_weights(top_model_weights_path)\n",
    "    json_string = model.to_json()\n",
    "    open(os.path.join(f_model,'test_model.json'), 'w').write(json_string)\n",
    "\n",
    "    scores = model.evaluate(validation_data, y_test, verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svm_train_data = train_data.reshape(1700,25088)\n",
    "svm_test_data = validation_data.reshape(300,25088)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: : 14.67%\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='rbf', gamma=0.7, C=1.0)\n",
    "clf.fit(svm_train_data, y_train.ravel())\n",
    "score = clf.score(svm_test_data, y_test.ravel())\n",
    "print(\"%s: %.2f%%\" % (\"acc: \", score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
